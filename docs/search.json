[
  {
    "objectID": "class/3_method.html",
    "href": "class/3_method.html",
    "title": "3 データの種類とまとめ方",
    "section": "",
    "text": "現状を知る\n問いを明らかにする、特に因果関係を見つけるようなことを目指して調査が行われます。\n\n\n\n\n調査の方法にはさまざまなものがある。\n\n実験\nアーカイバルデータ分析\nアンケートデータ分分析\n観察データ分析\nインタビューデータ分析\n\nこの授業では、統計的な処理のできる定量データを扱います。\n\nただし、文字データはテキストマイニングなどの方法で定量データ化が可能ですが本授業では扱いません。\n\n\n\n\n\nマウスを使った医学・薬学の実験\n大規模観測装置を使った天文学・物理学実験\n学生等を参加者とした心理学や経済学，経営学の実験\n実際の企業や政府を取り巻く制度や法律の変化を使った自然実験\n実際の企業や政府の行動を変化させて試してみる現場順実験\n\n\n\n\n\n企業の公表財務データ\n社内の人事・会計データ\nプロ野球選手の成績・年俸データ\n国勢調査や各種政府統計データ\n文章データ\n\n\n\n\n\n自分でアンケートを設計して得たデータ\n\n\n\n\n\n定量的観察データ（交通量調査など）\n定性的観察データ（現場での参与観察）\n\n\n\n\n\n当事者に直接質問を投げかける（構造化インタビュー・半構造化インタビュー）\nテーマについて自由に話してもらう（フォーカスグループインタビュー）\n\n\n\n\n\n調査の際には\n\n調査の目的に合っているか\nより厳密な証拠が得られる方法はないか\n\nといった基準で選択することが必要。特に後者についてお話しします\n\nEBM (Evidence Based Medicine: 根拠に基づいた医療)\n\n医学研究での考え方、それぞれの調査方法から得られる証拠はその確からしさ、根拠の強さに違いがあることを前提に、証拠のレベルを設定、より高いレベルの根拠をもとに医療行為の方法を決めよう、と言うもの\nこの考え方は、EBMgt（Evidence Based Management：根拠に基づいたマネジメント）として経営学に応用されたり、EBPM (Evidence Based Policy Making: 根拠に基づく政策決定)として政策決定に応用されたりしています。\nこの考え方に従うと、もし可能ならばより高いエビデンスレベルが得られる方法を選択することが望ましくなります。"
  },
  {
    "objectID": "class/3_method.html#調査の目的",
    "href": "class/3_method.html#調査の目的",
    "title": "3 データの種類とまとめ方",
    "section": "",
    "text": "現状を知る\n問いを明らかにする、特に因果関係を見つけるようなことを目指して調査が行われます。"
  },
  {
    "objectID": "class/3_method.html#調査の方法",
    "href": "class/3_method.html#調査の方法",
    "title": "3 データの種類とまとめ方",
    "section": "",
    "text": "調査の方法にはさまざまなものがある。\n\n実験\nアーカイバルデータ分析\nアンケートデータ分分析\n観察データ分析\nインタビューデータ分析\n\nこの授業では、統計的な処理のできる定量データを扱います。\n\nただし、文字データはテキストマイニングなどの方法で定量データ化が可能ですが本授業では扱いません。\n\n\n\n\n\nマウスを使った医学・薬学の実験\n大規模観測装置を使った天文学・物理学実験\n学生等を参加者とした心理学や経済学，経営学の実験\n実際の企業や政府を取り巻く制度や法律の変化を使った自然実験\n実際の企業や政府の行動を変化させて試してみる現場順実験\n\n\n\n\n\n企業の公表財務データ\n社内の人事・会計データ\nプロ野球選手の成績・年俸データ\n国勢調査や各種政府統計データ\n文章データ\n\n\n\n\n\n自分でアンケートを設計して得たデータ\n\n\n\n\n\n定量的観察データ（交通量調査など）\n定性的観察データ（現場での参与観察）\n\n\n\n\n\n当事者に直接質問を投げかける（構造化インタビュー・半構造化インタビュー）\nテーマについて自由に話してもらう（フォーカスグループインタビュー）\n\n\n\n\n\n調査の際には\n\n調査の目的に合っているか\nより厳密な証拠が得られる方法はないか\n\nといった基準で選択することが必要。特に後者についてお話しします\n\nEBM (Evidence Based Medicine: 根拠に基づいた医療)\n\n医学研究での考え方、それぞれの調査方法から得られる証拠はその確からしさ、根拠の強さに違いがあることを前提に、証拠のレベルを設定、より高いレベルの根拠をもとに医療行為の方法を決めよう、と言うもの\nこの考え方は、EBMgt（Evidence Based Management：根拠に基づいたマネジメント）として経営学に応用されたり、EBPM (Evidence Based Policy Making: 根拠に基づく政策決定)として政策決定に応用されたりしています。\nこの考え方に従うと、もし可能ならばより高いエビデンスレベルが得られる方法を選択することが望ましくなります。"
  },
  {
    "objectID": "class/3_method.html#予測",
    "href": "class/3_method.html#予測",
    "title": "3 データの種類とまとめ方",
    "section": "2.1 予測",
    "text": "2.1 予測\n\n天気予報\n株価予測\n販売予想\n\n\n2.1.1 予測の方法\n\nなんらかの法則を見出して，それが続くと仮定して未来を予測する\nデータを使って予測する"
  },
  {
    "objectID": "class/3_method.html#発見",
    "href": "class/3_method.html#発見",
    "title": "3 データの種類とまとめ方",
    "section": "2.2 発見",
    "text": "2.2 発見\n\n2.2.1 グルーピング・クラスタリング\n多くのデータをいくつかのグループに分ける。\n\n性別ごとに分ける\n年代ごとに分ける\n国籍ごとに分ける\n業界ごとに分ける\n\nあらかじめ分け方が決まっていない場合には，データ自身にグループを作成させるクラスタリングを行う\n\n\n2.2.2 相関分析\n2種類のデータの関係の強弱を相関という。\n身長と体重には相関があるが，身長と年収には相関はない\n\n\nCode\n#パッケージの読み込み\nlibrary(tidyverse) #様々な機能の統合パッケージ\nlibrary(magrittr) #コードを見やすくする\nlibrary(stargazer)\nlibrary(gtsummary)"
  },
  {
    "objectID": "class/3_method.html#課題",
    "href": "class/3_method.html#課題",
    "title": "3 データの種類とまとめ方",
    "section": "3.1 課題",
    "text": "3.1 課題\n以下のデータの各列はそれぞれどの尺度ですか。ただし\n\nid: 学籍番号\nclass: クラス\ngender: 性別\ntest: テストの点\nhometown: 出身地\n\n\n\nCode\ndata3 &lt;- read_csv(\"data/data3.csv\")\ndata3"
  },
  {
    "objectID": "class/3_method.html#rが理解しているデータの種類",
    "href": "class/3_method.html#rが理解しているデータの種類",
    "title": "3 データの種類とまとめ方",
    "section": "3.2 Rが理解しているデータの種類",
    "text": "3.2 Rが理解しているデータの種類\nデータの種類にはいくつかあるということでしたが，rにもそれに（完全にではないけれど）対応したデータの種類があります。\n\nnumeric (num数値型)：数値データ\ncharacter (chr文字列型)：文字データ\nfactor (fctr因子型)：カテゴリデータ\nlogical (lgl論理値型)：trueかfalseの2択データ\n\nエクセルやcsvファイルを読み込んだとき，Rは自動でこれらのうちのどれかとして読み取ります。どの種類として読み込まれたかは，画面右上のEnvironmentタブにあるDataウインドウから確認可能です。また，単にデータ名を実行するもしくはstr(データ名)でも確認可能です\n\n\nCode\nstr(data3)\n\n\nspc_tbl_ [30 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id      : num [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n $ class   : num [1:30] 1 1 1 1 1 1 1 1 1 1 ...\n $ gender  : chr [1:30] \"男\" \"女\" \"女\" \"女\" ...\n $ test    : num [1:30] 100 20 60 80 40 90 30 60 90 30 ...\n $ hometown: chr [1:30] \"京都\" \"京都\" \"大阪\" \"兵庫\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   class = col_double(),\n  ..   gender = col_character(),\n  ..   test = col_double(),\n  ..   hometown = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n初期状態では，genderとhometownがchr（文字列），それ以外がnum（数値）になっています。しかし，例えばidやclassは名義尺度であるべきです。\n後で使うclassをカテゴリデータに変えてみます。使うコマンドはas.factor(変えたい変数)です。\n\n\nCode\ndata3 %&lt;&gt;%\n  mutate(class = as.factor(class))\n\n\n1行目は，変えたいデータです。以下のように書いても同じです\ndata3 &lt;- data3 |&gt;\n2行目のmutate(新しい変数名 = 指示) は，新しい変数（列）を足すコマンドです。現在ある列名と同じものを指定すると上書きされます。今回は，classという数値変数をカテゴリ変数に変えたものを，元と同じclassという名前で作成（上書き）しています。\n文字列については，分析の際には自動的にカテゴリ変数として扱われるので，特段の変更処理は必要ありません。"
  },
  {
    "objectID": "class/8_regress.html",
    "href": "class/8_regress.html",
    "title": "8 単回帰分析",
    "section": "",
    "text": "Code\n1rm(list=ls()); gc();  gc();\n2if (!require(\"pacman\")) install.packages(\"pacman\")\n3pacman::p_load(tidyverse, magrittr,estimatr,car,modelsummary,ggrepel,patchwork)\n\n\n\n1\n\n前の作業など，rのメモリに入っているものをリセットするコマンド\n\n2\n\nパッケージ管理用のパッケージであるpacmanが入っていない場合はインストール\n\n3\n\n複数のパッケージを一度に呼び出す\nデータの読み込み\nCode\nice4_1 &lt;- read_csv(\"data/ice4_1.csv\")\nice4_1\n気温はkion，客数はkyakuという名前になっていることを確認します。\nその上でまず，データの散布図と，それにフィットする直線を書いてみます。\nCode\n1g &lt;- ggplot(data = ice4_1,\n2            aes(x = kion, y = kyaku)\n            ) %&gt;% \n3  + geom_point() %&gt;%\n4  + geom_smooth(method = \"lm\",se=FALSE)\n\nplot(g)\n\n\n\n1\n\n使うデータを指定\n\n2\n\nx軸とy軸を指定\n\n3\n\n散布図を作成\n\n4\n\n散布図にフィットする直線を書く。方法は，線形モデル(lm)\nこれは，自動で線が引かれていますが，例えばこんな線もあり得そうでもあります。\nCode\ng &lt;- ggplot(data = ice4_1, #使うデータを指定\n            aes(x = kion, y = kyaku) #x軸とy軸を指定\n            ) %&gt;% \n  + geom_point() %&gt;% #散布図を作成\n  + geom_smooth(method = \"lm\",se=FALSE) %&gt;% \n  + geom_hline(aes(yintercept=320),\n1               color = \"salmon\") %&gt;%\n  + geom_abline(intercept = 150, slope = 5,\n2                color = \"yellowgreen\")\n\n#散布図にフィットする直線を書く。方法は，線形モデル(lm)\nplot(g)\n\n\n\n1\n\n高さ320の水平線\n\n2\n\n傾き5，切片150の直線\nじゃあ，どんな線が最も良い線なのか，それを決めて線を引く，というか線の式を求めるのが回帰分析です。"
  },
  {
    "objectID": "class/8_regress.html#最小二乗法を解く",
    "href": "class/8_regress.html#最小二乗法を解く",
    "title": "8 単回帰分析",
    "section": "1.1 最小二乗法を解く",
    "text": "1.1 最小二乗法を解く\n数式で表すと\n\\[\n\\sum_{i=1}^n \\hat{u}_i^2= \\sum_{i=1}^n (y_i -\\hat{\\beta_0}-\\hat{\\beta_1}x_1)^2\n\\tag{1}\\]\nが最も小さくなる\\(\\beta_0\\)と\\(\\beta_1\\)を求めれば良い。2次関数の最小値問題。微分して0，とすると計算しやすいので，\\(\\beta_0\\)と\\(\\beta_1\\)をそれそれ微分1して\n\\[\n\\begin{equation}\\left\\{ \\,    \\begin{aligned}&\\frac{\\partial \\Sigma}{\\partial \\hat{\\beta_0}} = \\sum_{i=1}^n (y_i -\\hat{\\beta_0}-\\hat{\\beta_1}x_1) = 0 \\\\&\\frac{\\partial \\Sigma}{\\partial \\hat{\\beta_1}} = \\sum_{i=1}^n x_i(y_i -\\hat{\\beta_0}-\\hat{\\beta_1}x_1) = 0  \\end{aligned}\\right.\\end{equation}\n\\tag{2}\\]\nという連立方程式を解けば良い。\n\n\n\n\n\n\nヒント\n\n\n\n\\(\\bar{x}=\\dfrac{1}{n}\\sum_{i=1}^nx_i\\)とする\n\n\\(\\Sigma^n_{i=1}x_i(x_i-\\bar x) = \\Sigma^n_{i=1}(x_i-\\bar x)(x_i-\\bar x)\\)2\n\\(\\Sigma^n_{i=1}y_i(x_i-\\bar x) = \\Sigma^n_{i=1}x_i(y_i-\\bar y) = \\Sigma^n_{i=1}(x_i-\\bar x)(y_i-\\bar y)\\)\n\n\n\n\\[\n\\begin{equation}\n\\left\\{ \\,   \n\\begin{split}\n&\\sum_{i=1}^n (y_i -\\hat{\\beta_0}-\\hat{\\beta_1}x_1) = 0  \\\\\n&\\sum_{i=1}^n x_i(y_i -\\hat{\\beta_0}-\\hat{\\beta_1}x_1) = 0  \n\\end{split}\n\\right.\n\\end{equation}\n\\tag{3}\\]\n上の式から\n\\(\\begin{split}&\\Sigma y_i - n \\hat{\\beta_0} - \\hat{\\beta_1}\\Sigma x_i = 0 \\\\\\hat{\\beta_0} &= \\frac{1}{n} (\\Sigma y_i - \\hat{\\beta_1}\\Sigma x_i) \\\\&= \\bar{y} - \\hat{\\beta_1} \\bar{x}\\end{split}\\)\n下の式に代入\n\\(\\begin{split}\\Sigma x_i \\{y_i - (\\bar{y} - \\hat{\\beta_1}\\bar{x}) - \\hat{\\beta_1}x_i\\} &= 0 \\\\ \\Sigma x_i \\{(y_i - \\bar{y}) - \\hat{\\beta_1}(x_i - \\bar{x})\\} &= 0 \\\\\\Sigma x_i (y_i - \\bar{y}) - \\hat{\\beta_1}\\Sigma x_i (x_i - \\bar{x}) &= 0 \\\\\\end{split}\\)\nヒントから\n\\(\\Sigma (x_i - \\bar{x})(y_i - \\bar{y}) - \\hat{\\beta_1}\\Sigma (x_i - \\bar{x}) (x_i - \\bar{x}) = 0\\)\n\\[\n\\hat{\\beta_1} = \\dfrac{\\Sigma (x_i - \\bar{x})(y_i - \\bar{y})}{ \\Sigma  (x_i - \\bar{x})^2} = \\dfrac{ x \\mbox{と}y\\mbox{の共分散}}{ x\\mbox{の分散}}\n\\tag{4}\\]\n\\[\n\\hat{\\beta_0} = \\bar{y} - \\dfrac{\\Sigma (x_i - \\bar{x})(y_i - \\bar{y})}{ \\Sigma  (x_i - \\bar{x})^2} \\bar{x}\n\\tag{5}\\]"
  },
  {
    "objectID": "class/8_regress.html#通過テスト",
    "href": "class/8_regress.html#通過テスト",
    "title": "8 単回帰分析",
    "section": "3.1 通過テスト",
    "text": "3.1 通過テスト\n\n\nCode\nice4_9 &lt;- read_csv(\"data/ice1_9.csv\")\n\n\n\nlm(gpa ~ exam, data = ice4_9) -&gt; kekka\n\n\nmsummary(kekka,\n         gof_omit = \"Log.Lik.|AIC|BIC\",\n         title = \"\",          # タイトル\n         stars = TRUE)\n\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n−1.797+\n\n\n\n(0.896)\n\n\nexam\n0.008***\n\n\n\n(0.002)\n\n\nNum.Obs.\n19\n\n\nR2\n0.580\n\n\nR2 Adj.\n0.556\n\n\nF\n23.509\n\n\nRMSE\n0.48\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\nCode\n# 予測値の作成\nnewdata &lt;- tibble(exam = c(400,500,600,700))\npredict(kekka,new = newdata)\n\n\n       1        2        3        4 \n1.429565 2.236329 3.043092 3.849855"
  },
  {
    "objectID": "class/8_regress.html#footnotes",
    "href": "class/8_regress.html#footnotes",
    "title": "8 単回帰分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nバラバラにして微分してまとめ直してもできますが，合成関数の微分の考え方を知ってると即座に計算できます。↩︎\n\\[\n\\begin{split}\n\\Sigma^n_{i=1}&x_i(x_i-\\bar x)  \\\\\n& = \\Sigma^n_{i=1} x_i^2 - \\bar x \\Sigma^n_{i=1} x_i \\\\\n& = \\Sigma^n_{i=1}x_i^2 - n(\\bar x)^2\n\\end{split}\n\\]\n一方で\n\\[\n\\begin{split}\n\\Sigma^n_{i=1}&(x_i-\\bar x)(x_i-\\bar x)  \\\\\n& = \\Sigma^n_{i=1} (x_i^2 - 2 x_i \\bar x +(\\bar x)^2) \\\\\n& = \\Sigma^n_{i=1}x_i^2 -2 \\bar x \\Sigma^n_{i=1}x_i + (\\bar x)^2\\\\\n& = \\Sigma^n_{i=1}x_i^2 - n(\\bar x)^2 \\\\\n\\end{split}\n\\]↩︎"
  },
  {
    "objectID": "class/index.html",
    "href": "class/index.html",
    "title": "授業",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nundefined\n\n\n1 イントロダクション\n\n\n\n\nundefined\n\n\n11 内省変数・外生変数と因果推論\n\n\n\n\nundefined\n\n\n2 分析環境の構築\n\n\n\n\nundefined\n\n\n3 データの種類とまとめ方\n\n\n\n\nundefined\n\n\n4 データを要約する\n\n\n\n\nundefined\n\n\n5 クロス集計・相関\n\n\n\n\nundefined\n\n\n6 母集団と標本\n\n\n\n\nundefined\n\n\n7 検定\n\n\n\n\nundefined\n\n\n8 単回帰分析\n\n\n\n\nundefined\n\n\n9 重回帰分析\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "class/1_intro.html",
    "href": "class/1_intro.html",
    "title": "1 イントロダクション",
    "section": "",
    "text": "学士（経営学），神戸大学2011年\n修士（経営学），神戸大学2013年\n博士（経営学），神戸大学2016年\n\n\n\n\n\n松山大学経営学部講師→准教授 (2015-2022)\n\nWU Vienna, Research Visitor (2019)\nGeorgetown University Visiting Scholar (2019-2020)\n\n神戸大学大学院経営学研究科准教授 (2022-)\n\n\n\n\n\n\n管理会計，特に業績評価システム\n\n従業員を評価し，報酬を与えることでやる気になってもらう仕組み\n\nどんな目標を設定すれば良いか？\n目標は途中で変えるべきか？\n上司の主観的評価の落とし穴は？\n創造的（クリエイティブ）なタスクはどう評価する？\n\n\n企業のデータや実験により得たデータ，公表財務データなどを統計的に分析することで，これらの問題を研究しています。"
  },
  {
    "objectID": "class/1_intro.html#略歴",
    "href": "class/1_intro.html#略歴",
    "title": "1 イントロダクション",
    "section": "",
    "text": "学士（経営学），神戸大学2011年\n修士（経営学），神戸大学2013年\n博士（経営学），神戸大学2016年\n\n\n\n\n\n松山大学経営学部講師→准教授 (2015-2022)\n\nWU Vienna, Research Visitor (2019)\nGeorgetown University Visiting Scholar (2019-2020)\n\n神戸大学大学院経営学研究科准教授 (2022-)\n\n\n\n\n\n\n管理会計，特に業績評価システム\n\n従業員を評価し，報酬を与えることでやる気になってもらう仕組み\n\nどんな目標を設定すれば良いか？\n目標は途中で変えるべきか？\n上司の主観的評価の落とし穴は？\n創造的（クリエイティブ）なタスクはどう評価する？\n\n\n企業のデータや実験により得たデータ，公表財務データなどを統計的に分析することで，これらの問題を研究しています。"
  },
  {
    "objectID": "class/1_intro.html#エビデンスベースト-evidence-basedという考え方",
    "href": "class/1_intro.html#エビデンスベースト-evidence-basedという考え方",
    "title": "1 イントロダクション",
    "section": "2.2 エビデンス・ベースト (evidence-based)という考え方",
    "text": "2.2 エビデンス・ベースト (evidence-based)という考え方\n\n元々は医療分野の根拠に基づく医療（Evidence-Based Medicine: EBM）\n症例や臨床経験だけでなく，実験等で得られた証拠など，科学的根拠を活用した医療行為を行おう，という考え方\nこの考え方は，公共政策の分野（Evidence-Based Policy Making）や経営分野（Evidence-Based Management）に応用されつつある。\nこの考えの中では，エビデンスには複数のレベルがあるとされる。\n\n\n2.2.1 参考: エビデンスレベル\n\nこれは，根拠に基づく医療（Evidence Based Medicine: EBM）という考え方の中の言葉\n各研究方法から得られる証拠（エビデンス）をその信頼度で分類している\n根拠に基づく政策立案（EBPM）や，根拠に基づく経営（EBMgt） (Rousseau 2006) として，経営学を含む他分野でも紹介されつつある\n\n\nエビデンスレベル一覧（Wikipediaから）\n\n\nLevel\n内容\n\n\n\n\n1a\nランダム化比較試験のメタアナリシス\n\n\n1b\n少なくとも一つのランダム化比較試験 (RCT)\n\n\n2a\nランダム割付を伴わない同時コントロールを伴うコホート研究（前向き研究、prospective study, concurrent cohort study）\n\n\n2b\nランダム割付を伴わない過去のコントロールを伴うコホート研究 (historical cohort study, retrospective cohort study)\n\n\n3\n症例対照研究（ケースコントロール、後ろ向き研究）\n\n\n4\n処置前後の比較の前後比較、対照群を伴わない研究\n\n\n5\n症例報告、ケースシリーズ\n\n\n6\n専門家個人の意見（専門家委員会報告を含む）\n\n\n\n\n\n2.2.2 エビデンスの提供元としての社会調査\n\n社会調査によって得られたデータの分析結果は，国家・地方公共団体の政策や企業の経営判断に役立てられる。\nしかし，調査の仕方がまずかったり，分析の仕方がまずいと誤った結果をエビデンスとして提供してしまう可能性も\n\n関係のないものを関係あると示す\n関係のあるものを関係ないと示す\n正の関係のものを負の関係として示す"
  },
  {
    "objectID": "class/1_intro.html#リサーチクエスチョンの設定",
    "href": "class/1_intro.html#リサーチクエスチョンの設定",
    "title": "1 イントロダクション",
    "section": "3.1 リサーチクエスチョンの設定",
    "text": "3.1 リサーチクエスチョンの設定\n\n調査の目的は，何かしらの新しい知識や情報を得ることにある\n社会調査は調査なので，何かしら調査するべき課題・疑問がある\n\nまだわかっていないことの中で社会的もしくは理論的に重要なもの"
  },
  {
    "objectID": "class/1_intro.html#リサーチデザインの設定",
    "href": "class/1_intro.html#リサーチデザインの設定",
    "title": "1 イントロダクション",
    "section": "3.2 リサーチ・デザインの設定",
    "text": "3.2 リサーチ・デザインの設定\n\n問が定まっても，闇雲にアンケートを行えば良いわけではない。\n\n問いに関連してすでにわかっていることは何かを把握する\n\n理論や専門知識，過去の調査結果\n\n問いの答えとその理由に関する仮説を立てる\nデータをどのように取るのかを検討する"
  },
  {
    "objectID": "class/1_intro.html#データ収集分析",
    "href": "class/1_intro.html#データ収集分析",
    "title": "1 イントロダクション",
    "section": "3.3 データ収集・分析",
    "text": "3.3 データ収集・分析\n\nリサーチデザインに従って収集したデータを適切に分析して，仮説を検証する\n仮説の検証結果を根拠に当初の問いの答えを決める"
  },
  {
    "objectID": "class/1_intro.html#定量的データの分析",
    "href": "class/1_intro.html#定量的データの分析",
    "title": "1 イントロダクション",
    "section": "4.1 定量的データの分析",
    "text": "4.1 定量的データの分析\n\n社会調査の一連の流れには，たくさんの論点があり全てを15回で扱うことはできません。\n\n\n\n\n\n\n\nNote\n\n\n\n問いの設定や，リサーチデザインについては，例えば 佐藤 (2015a), 佐藤 (2015b), 伊丹 (2001) などが詳しいです。また，事例が経営学に寄っていますが， 田村 (2006), 須田 (2019) などもわかりやすいです。\n\n\n\n社会調査士プログラムの1授業として，この授業では定量的なデータの分析部分を中心に扱います。\n\nデータの種類\nデータのまとめ方\n母集団と標本\n推定と検定\n回帰分析\n分散分析\n\nこれは，得られたデータからなるべく間違いのない結果を提示するための方法に関する部分です"
  },
  {
    "objectID": "class/1_intro.html#プログラミング言語rを使った分析",
    "href": "class/1_intro.html#プログラミング言語rを使った分析",
    "title": "1 イントロダクション",
    "section": "4.2 プログラミング言語Rを使った分析",
    "text": "4.2 プログラミング言語Rを使った分析\n\nこの授業では，特に統計的な処理にRというプログラミング言語を使います\nRは特に統計分析に特化したプログラミング言語で，Pythonのような汎用性がない代わりに，統計的な処理に関わる機能や操作性が高いです\n\nただし，統計処理に関わる前後の処理も得意で，例えばレポートやスライド資料も作れます\nこの授業資料も全部Rで作っています"
  },
  {
    "objectID": "class/5_correlation.html",
    "href": "class/5_correlation.html",
    "title": "5 クロス集計・相関",
    "section": "",
    "text": "前回は，1つの変数の様子を表す代表値として平均や中央値，ばらつき（分散・標準偏差）等を扱いました。\n今回は，二つの変数の間の関係に関わる内容を扱います。具体的には，二つの変数の状況によって場合分けした表であるクロス集計表や，二つの変数を図示した散布図，二つの変数間の関係の強さを表す相関係数などを学習します。\n\n\nCode\n1rm(list=ls()); gc();  gc();\n2if (!require(\"pacman\")) install.packages(\"pacman\")\n3pacman::p_load(tidyverse, magrittr,estimatr,car,modelsummary,ggrepel,patchwork)\n\n\n\n1\n\n前の作業など，rのメモリに入っているものをリセットするコマンド\n\n2\n\nパッケージ管理用のパッケージであるpacmanが入っていない場合はインストール\n\n3\n\n複数のパッケージを一度に呼び出す\n\n\n\n\n統計的分析を行う際に考えるののは，ここの変数（例えば質問項目ひとつひとつ）の平均や分散だけではない。\n多くの場合複数の変数の関係を見たくなる。ここでは，複数の変数間の関係についてを表す数値やグラフ・表について扱います。\n\n\nCode\nicedata &lt;- read_csv(\"data/ice1_1.csv\")\n\n\n\n\n二つの変数，例えば気温とアイスクリーム屋さんの客数との関係を知りたい場合，最も単純な図示の方法は，x軸を気温，y軸を客数として，日毎や時間毎のデータを書き込んでいくこと。これを散布図と言います。\n　データを読み込んで，散布図を書いています。散布図を書く一番簡単なコマンドはplot(x軸にしたい変数, y軸にしたい変数)です。 　\n\n\nCode\nicedata %$%\n  plot(kion,kyaku)\n\nicedata %$%\n  plot(kion,kyaku)\n\n\n\n\n\nカスタマイズもいくらかできます。\n\n\nCode\nicedata %$%\n  plot(kion,kyaku,\n       pch = 0, cex = 1, col = \"blue\")\n\n\n\n\n\nggplot2というパッケージ(tidyverseの中に入っている)を使うと高度にカスタマイズしたグラフが書けます。\n\n\nCode\na &lt;- ggplot(data = icedata, mapping = aes(kion, kyaku)) %&gt;% #グラフを作成\n    + geom_point() #書く数値を点(point)で書く\nplot(a)\n\n\n\n\n\nCode\nb &lt;- ggplot(data = icedata, mapping = aes(kion, kyaku, label = day)) %&gt;% #グラフを作成\n    + geom_point() %&gt;% #書く数値を点(point)で書く\n    + geom_text_repel() #各点にラベルをつける\nplot(b)\n\n\n\n\n\nここで，散布図から視覚的にわかることとして，右肩上がりだと正の関係（片方が高いともう片方も高い），右肩下がりだと負の関係，バラバラに散らばっていると関係がなさそう，ということ。\n\n\nCode\nset.seed(123)\nx_p &lt;- rnorm(100,10,10)\ny_p &lt;- x_p + rnorm(100,10,5)\n\nx &lt;- rnorm(100,10,10)\ny &lt;- rnorm(100,10,10)\n\nx_n &lt;- rnorm(100,10,10)\ny_n &lt;- -x_n - rnorm(100,10,5)\n\n\nplot(x_p,y_p)\n\n\n\n\n\nCode\nplot(x,y)\n\n\n\n\n\nCode\nplot(x_n,y_n)\n\n\n\n\n\n\n\n\nこれを数値で表すのが共分散と相関係数です。共分散は以下のように計算されます。\n\\[\nCov_{xy}=\\frac{1}{n}\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\n\\]\n\n変数xの値から平均値をひく\\(\\left( x_i - \\bar{x}\\right)\\)。yも同様\\(\\left( y_i - \\bar{y}\\right)\\)\n両者を掛け合わせる\\(\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\\)\nこれをデータ1からnまで順番にやって全てを足し合わせる\\(\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\\)\nデータのサイズnで割る\n\nRでは，cov()関数で計算できます\n\n\nCode\ncov(x,y)\n\n\n[1] -4.426973\n\n\nCode\ncov(x_p,y_p)\n\n\n[1] 81.13723\n\n\n値が大きいほど関係が強い。ただし，データの単位に依存するので，どれぐらい数字が大きかったら関係が強いと言えるのかはわからない。\nそこで，共分散を各変数の標準偏差の積で割って単位に依存しない基準を作る。これを相関係数という\n\\[\nr = \\frac{Cov_{xy}}{SD_xSD_y} = \\frac{Cov_{xy}}{\\sqrt{\\frac{1}{n}\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)^2}\\sqrt{\\frac{1}{n}\\Sigma^n_{i=1}\\left( y_i - \\bar{y}\\right)^2}}\n\\]\n相関係数rは，-1以上1以下の数値をとります。関係が強いほど-1もしくは1に近くなります。\nこれで，散布図で見た関係性の違いを数値で表すことができました。\n\n\nCode\ncov(x,y)/(sqrt(var(x))*sqrt(var(y)))\n\n\n[1] -0.04486571\n\n\n相関係数(correlation)は，cor()関数でできます。\n\n\n\n\nCode\ncor(x_p,y_p)\n\n\n[1] 0.8786993\n\n\n\n\n\n\n\n\n\n\nCode\ncor(x,y)\n\n\n[1] -0.04486571\n\n\n\n\n\n\n\n\n\n\nCode\ncor(x_n,y_n)\n\n\n[1] -0.9210776\n\n\n\n\n\n\n\n\n\n\n\n\n複数の変数のペア毎の相関係数を行列形式で表示するもの。\n\n\nCode\n1data.frame(x_p,y_p,x,y,x_n,y_n) |&gt;\n2  datasummary_correlation()\n\n\n\n1\n\n先程まで使っていたデータを一つに繋げてdata.frame形式にして\n\n2\n\nコマンドdatasummary_correlation()で相関行列を出力（modelsummaryパッケージの一部）\n\n\n\n\n\n\n\n\nx_p\ny_p\nx\ny\nx_n\ny_n\n\n\n\n\nx_p\n1\n.\n.\n.\n.\n.\n\n\ny_p\n.88\n1\n.\n.\n.\n.\n\n\nx\n−.13\n−.10\n1\n.\n.\n.\n\n\ny\n−.04\n−.02\n−.04\n1\n.\n.\n\n\nx_n\n−.19\n−.24\n−.02\n−.02\n1\n.\n\n\ny_n\n.18\n.20\n.01\n.05\n−.92\n1\n\n\n\n\n\n\n\n\n\nCode\nanscombe # Rの組み込みパッケージ datasets によりアンスコムの例のデータが利用できます\n\n\n\n\n  \n\n\n\nCode\nanscombe_long &lt;- \n  anscombe |&gt; \n  tidyr::pivot_longer(\n    tidyselect::everything(),\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\")\ncourse_colors &lt;- c(\"#364968\", \"#fddf97\", \"#e09664\", \"#6c4343\", \"#ffffff\")\n\n\nanscombe_long # アンスコムデータを縦長の形にしたもの\n\n\n\n\n  \n\n\n\nCode\n# 記述統計量（平均と分散）の算出\n# setがデータセットの種類を示します\n# set間で値に大きな差はありません\n# 相関係数も小数点第二位まではset間で同じ値となります\nanscombe_long |&gt; \n  group_by(set) |&gt; \n  summarise(across(.cols = c(x, y), .fns = list(mean = mean, sd = sd)),\n            .groups = \"keep\") |&gt; \n  summarise(across(.cols = contains(\"_\"), .fns = ~ round(.x, digits = 2))) |&gt; \n  left_join(\n    anscombe_long |&gt; \n      group_by(set) |&gt; \n      group_modify(~ tibble::tibble(cor = cor.test(.x$x, .x$y)$estimate)) |&gt; \n      ungroup() |&gt; \n      mutate(cor = round(cor, digits = 2)),\n    by = \"set\")\n\n\n\n\n  \n\n\n\nCode\nanscombe_long |&gt; \n  group_by(set) |&gt; \n  group_map(\n    ~ ggplot(.x, aes(x, y)) +\n      geom_point(color = course_colors[1]) +\n      geom_smooth(method = lm, \n                  se = FALSE, \n                  color = course_colors[2])) |&gt; \n  wrap_plots(ncol = 4)\n\n\n\n\n\nCode\n# ggsave(here(\"images/anscombes_quartet.png\"),\n#        width = 7,\n#        height = 2.2)\n\n\n\n\n\nデータice2_5.csvには以下の変数が入っています。\n\nshop\n\nお店のid番号\n\nkyori\n\n駅からの距離\n\nkyaku\n\n1日の客数\n\n\nこのデータから，客数と駅からの距離の\n\n散布図を書いてください\n相関係数を計算してください\n相関係数から読み取れることを説明してください\n\n1.2はコードをそのまま記入してください。3は文章で説明してください。\n\n\n\n\nCode\nicedata2 &lt;- read_csv(\"data/ice2_5.csv\") \n\n\n\n\n\nplot()関数を使った一番簡単な散布図です\n\n\nCode\nicedata2 %$%\n  plot(kyori, kyaku)"
  },
  {
    "objectID": "class/5_correlation.html#散布図",
    "href": "class/5_correlation.html#散布図",
    "title": "5 クロス集計・相関",
    "section": "",
    "text": "二つの変数，例えば気温とアイスクリーム屋さんの客数との関係を知りたい場合，最も単純な図示の方法は，x軸を気温，y軸を客数として，日毎や時間毎のデータを書き込んでいくこと。これを散布図と言います。\n　データを読み込んで，散布図を書いています。散布図を書く一番簡単なコマンドはplot(x軸にしたい変数, y軸にしたい変数)です。 　\n\n\nCode\nicedata %$%\n  plot(kion,kyaku)\n\nicedata %$%\n  plot(kion,kyaku)\n\n\n\n\n\nカスタマイズもいくらかできます。\n\n\nCode\nicedata %$%\n  plot(kion,kyaku,\n       pch = 0, cex = 1, col = \"blue\")\n\n\n\n\n\nggplot2というパッケージ(tidyverseの中に入っている)を使うと高度にカスタマイズしたグラフが書けます。\n\n\nCode\na &lt;- ggplot(data = icedata, mapping = aes(kion, kyaku)) %&gt;% #グラフを作成\n    + geom_point() #書く数値を点(point)で書く\nplot(a)\n\n\n\n\n\nCode\nb &lt;- ggplot(data = icedata, mapping = aes(kion, kyaku, label = day)) %&gt;% #グラフを作成\n    + geom_point() %&gt;% #書く数値を点(point)で書く\n    + geom_text_repel() #各点にラベルをつける\nplot(b)\n\n\n\n\n\nここで，散布図から視覚的にわかることとして，右肩上がりだと正の関係（片方が高いともう片方も高い），右肩下がりだと負の関係，バラバラに散らばっていると関係がなさそう，ということ。\n\n\nCode\nset.seed(123)\nx_p &lt;- rnorm(100,10,10)\ny_p &lt;- x_p + rnorm(100,10,5)\n\nx &lt;- rnorm(100,10,10)\ny &lt;- rnorm(100,10,10)\n\nx_n &lt;- rnorm(100,10,10)\ny_n &lt;- -x_n - rnorm(100,10,5)\n\n\nplot(x_p,y_p)\n\n\n\n\n\nCode\nplot(x,y)\n\n\n\n\n\nCode\nplot(x_n,y_n)"
  },
  {
    "objectID": "class/5_correlation.html#相関係数",
    "href": "class/5_correlation.html#相関係数",
    "title": "5 クロス集計・相関",
    "section": "",
    "text": "これを数値で表すのが共分散と相関係数です。共分散は以下のように計算されます。\n\\[\nCov_{xy}=\\frac{1}{n}\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\n\\]\n\n変数xの値から平均値をひく\\(\\left( x_i - \\bar{x}\\right)\\)。yも同様\\(\\left( y_i - \\bar{y}\\right)\\)\n両者を掛け合わせる\\(\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\\)\nこれをデータ1からnまで順番にやって全てを足し合わせる\\(\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left( y_i - \\bar{y}\\right)\\)\nデータのサイズnで割る\n\nRでは，cov()関数で計算できます\n\n\nCode\ncov(x,y)\n\n\n[1] -4.426973\n\n\nCode\ncov(x_p,y_p)\n\n\n[1] 81.13723\n\n\n値が大きいほど関係が強い。ただし，データの単位に依存するので，どれぐらい数字が大きかったら関係が強いと言えるのかはわからない。\nそこで，共分散を各変数の標準偏差の積で割って単位に依存しない基準を作る。これを相関係数という\n\\[\nr = \\frac{Cov_{xy}}{SD_xSD_y} = \\frac{Cov_{xy}}{\\sqrt{\\frac{1}{n}\\Sigma^n_{i=1}\\left( x_i - \\bar{x}\\right)^2}\\sqrt{\\frac{1}{n}\\Sigma^n_{i=1}\\left( y_i - \\bar{y}\\right)^2}}\n\\]\n相関係数rは，-1以上1以下の数値をとります。関係が強いほど-1もしくは1に近くなります。\nこれで，散布図で見た関係性の違いを数値で表すことができました。\n\n\nCode\ncov(x,y)/(sqrt(var(x))*sqrt(var(y)))\n\n\n[1] -0.04486571\n\n\n相関係数(correlation)は，cor()関数でできます。\n\n\n\n\nCode\ncor(x_p,y_p)\n\n\n[1] 0.8786993\n\n\n\n\n\n\n\n\n\n\nCode\ncor(x,y)\n\n\n[1] -0.04486571\n\n\n\n\n\n\n\n\n\n\nCode\ncor(x_n,y_n)\n\n\n[1] -0.9210776"
  },
  {
    "objectID": "class/5_correlation.html#相関行列",
    "href": "class/5_correlation.html#相関行列",
    "title": "5 クロス集計・相関",
    "section": "",
    "text": "複数の変数のペア毎の相関係数を行列形式で表示するもの。\n\n\nCode\n1data.frame(x_p,y_p,x,y,x_n,y_n) |&gt;\n2  datasummary_correlation()\n\n\n\n1\n\n先程まで使っていたデータを一つに繋げてdata.frame形式にして\n\n2\n\nコマンドdatasummary_correlation()で相関行列を出力（modelsummaryパッケージの一部）\n\n\n\n\n\n\n\n\nx_p\ny_p\nx\ny\nx_n\ny_n\n\n\n\n\nx_p\n1\n.\n.\n.\n.\n.\n\n\ny_p\n.88\n1\n.\n.\n.\n.\n\n\nx\n−.13\n−.10\n1\n.\n.\n.\n\n\ny\n−.04\n−.02\n−.04\n1\n.\n.\n\n\nx_n\n−.19\n−.24\n−.02\n−.02\n1\n.\n\n\ny_n\n.18\n.20\n.01\n.05\n−.92\n1\n\n\n\n\n\n\n\n\n\nCode\nanscombe # Rの組み込みパッケージ datasets によりアンスコムの例のデータが利用できます\n\n\n\n\n  \n\n\n\nCode\nanscombe_long &lt;- \n  anscombe |&gt; \n  tidyr::pivot_longer(\n    tidyselect::everything(),\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\")\ncourse_colors &lt;- c(\"#364968\", \"#fddf97\", \"#e09664\", \"#6c4343\", \"#ffffff\")\n\n\nanscombe_long # アンスコムデータを縦長の形にしたもの\n\n\n\n\n  \n\n\n\nCode\n# 記述統計量（平均と分散）の算出\n# setがデータセットの種類を示します\n# set間で値に大きな差はありません\n# 相関係数も小数点第二位まではset間で同じ値となります\nanscombe_long |&gt; \n  group_by(set) |&gt; \n  summarise(across(.cols = c(x, y), .fns = list(mean = mean, sd = sd)),\n            .groups = \"keep\") |&gt; \n  summarise(across(.cols = contains(\"_\"), .fns = ~ round(.x, digits = 2))) |&gt; \n  left_join(\n    anscombe_long |&gt; \n      group_by(set) |&gt; \n      group_modify(~ tibble::tibble(cor = cor.test(.x$x, .x$y)$estimate)) |&gt; \n      ungroup() |&gt; \n      mutate(cor = round(cor, digits = 2)),\n    by = \"set\")\n\n\n\n\n  \n\n\n\nCode\nanscombe_long |&gt; \n  group_by(set) |&gt; \n  group_map(\n    ~ ggplot(.x, aes(x, y)) +\n      geom_point(color = course_colors[1]) +\n      geom_smooth(method = lm, \n                  se = FALSE, \n                  color = course_colors[2])) |&gt; \n  wrap_plots(ncol = 4)\n\n\n\n\n\nCode\n# ggsave(here(\"images/anscombes_quartet.png\"),\n#        width = 7,\n#        height = 2.2)"
  },
  {
    "objectID": "class/5_correlation.html#実習",
    "href": "class/5_correlation.html#実習",
    "title": "5 クロス集計・相関",
    "section": "",
    "text": "データice2_5.csvには以下の変数が入っています。\n\nshop\n\nお店のid番号\n\nkyori\n\n駅からの距離\n\nkyaku\n\n1日の客数\n\n\nこのデータから，客数と駅からの距離の\n\n散布図を書いてください\n相関係数を計算してください\n相関係数から読み取れることを説明してください\n\n1.2はコードをそのまま記入してください。3は文章で説明してください。\n\n\n\n\nCode\nicedata2 &lt;- read_csv(\"data/ice2_5.csv\") \n\n\n\n\n\nplot()関数を使った一番簡単な散布図です\n\n\nCode\nicedata2 %$%\n  plot(kyori, kyaku)"
  },
  {
    "objectID": "class/4_data.html",
    "href": "class/4_data.html",
    "title": "4 データを要約する",
    "section": "",
    "text": "Code\n#パッケージの読み込み\nlibrary(tidyverse) #様々な機能の統合パッケージ\nlibrary(magrittr) #コードを見やすくする\nlibrary(stargazer)\nlibrary(gtsummary)"
  },
  {
    "objectID": "class/4_data.html#平均値",
    "href": "class/4_data.html#平均値",
    "title": "4 データを要約する",
    "section": "1.1 平均値",
    "text": "1.1 平均値\nデータに含まれる値をすべて足してデータの数で割った値。\\(\\bar X\\) とすると。\n\\[ \\bar X = (X_1 + X_2 + ... X_n )/n = \\frac{1}{n} \\Sigma_{i=1}^{n} X_i \\]\n平均値は，統計的推測に際して重要な性質を持っていますが，データの真ん中を表しているわけではないことに注意が必要です。\n\n\nCode\n1data3_1 &lt;- c(100,90,80,70,60,40,10)\nxbar &lt;- mean(data3_1) \nxbar\n\n#これは以下でも同じ\n2xbar2 = sum(data3_1) / length(data3_1)\nxbar2\n\n\n\n1\n\nデータを作成して，data3_1という名前で保存\n\n2\n\nsum() は()内で指定したデータを合計する関数，length() はデータの数（行数）を吐き出す関数。data3_1は7行なので7が吐き出される。\n\n\n\n\n[1] 64.28571\n[1] 64.28571"
  },
  {
    "objectID": "class/4_data.html#中央値",
    "href": "class/4_data.html#中央値",
    "title": "4 データを要約する",
    "section": "1.2 中央値",
    "text": "1.2 中央値\nデータを順番に並べてちょうど真ん中の値。\n\n\nCode\nmedian(data3_1)\n\n\n[1] 70\n\n\n平均値と中央値はそれぞれデータの代表的な値ではありますが，必ずしも一致しません。例えば以下のようなデータがあったとします。\n\n\nCode\nx &lt;- c(10, 10, 10, 10, 10, 10, 10, 20, 20, 30, 90, 100)\n\n\n平均と中央値はそれぞれ違います。\n\n\nCode\nmean(x)\n\n\n[1] 27.5\n\n\nCode\nmedian(x)\n\n\n[1] 10\n\n\n\n\n\n\n\n一致する場合もあります。"
  },
  {
    "objectID": "class/4_data.html#最大値最小値",
    "href": "class/4_data.html#最大値最小値",
    "title": "4 データを要約する",
    "section": "1.3 最大値・最小値",
    "text": "1.3 最大値・最小値\nそのまま，最大の値と最小の値\n\n\nCode\nmax(data3_1)\n\n\n[1] 100\n\n\nCode\nmin(data3_1)\n\n\n[1] 10"
  },
  {
    "objectID": "class/4_data.html#分散",
    "href": "class/4_data.html#分散",
    "title": "4 データを要約する",
    "section": "1.4 分散",
    "text": "1.4 分散\nデータのばらつき度合いを表します。例えば，A, Bという２つのクラスがあるとします。ある教科のテストの平均，中央値が両クラスとも60だったとしても，\n\n20,60,100,30,90\n60,60,60,60,60\n\nというように特典の分布が全く異なる場合があり得ます。この違いは平均や中央値だけでは読み取れません。この違いを表す，平均からのばらつき度合いを把握する指標が分散です。\n平均からの距離 （\\(\\bar X - X_i\\)）は，プラスにもマイナスにもなり，足し合わせたら0になってしまうので，これを2乗した\\((\\bar X - X_i)^2\\)をデータの数だけ足し合わせて，データの数で割ったものを分散とします。\n\\[\n\\text{分散} = \\frac{1}{n} \\Sigma_{i = 1}^n(\\bar X - X_i)^2\n\\]\n\n\nCode\ndata3_2a &lt;- c(20,60,100,30,90)\ndata3_2b &lt;- c(60,60,60,60,60)\n\nmeana &lt;- mean(data3_2a)\nsa &lt;- meana -　data3_2a\nsua &lt;- sum(sa^2) \n1分散a &lt;- sua / length(data3_2a)\n\n分散b = sum((mean(data3_2b) - data3_2b)^2)/length(data3_2b)\n\n分散a\n分散b\n\n\n\n1\n\nこんなふうに変数名は日本語でも大丈夫ですが，全角半角の切り替えが面倒くさかったり，ミスの元なのであまりやらない方がいいと思います。\n\n\n\n\n[1] 1000\n[1] 0\n\n\nAの分散は1000，Bの分散は0。"
  },
  {
    "objectID": "class/4_data.html#標準偏差",
    "href": "class/4_data.html#標準偏差",
    "title": "4 データを要約する",
    "section": "1.5 標準偏差",
    "text": "1.5 標準偏差\nでも，この数値は何を意味しているのかがわからないです。なぜなら，元の点数（100点満点）を2乗しているからです。これをルートを取って元に戻すと，元の数値や平均値と同じ単位になります。分散のルートを取ったものを標準偏差といいます。\n\\[\n\\text{標準偏差} = \\sqrt{\\text{分散}}\n\\]\n\n\nCode\n標準偏差A &lt;- sqrt(分散a)\n標準偏差A\n\n\n[1] 31.62278"
  },
  {
    "objectID": "class/4_data.html#度数分布表",
    "href": "class/4_data.html#度数分布表",
    "title": "4 データを要約する",
    "section": "2.1 度数分布表",
    "text": "2.1 度数分布表\n名義尺度や順序尺度（もしくは範囲を区切った量的変数）ごとに当てはまるサンプルサイズを集計した表です。\n\n\nCode\ndata3 &lt;- read_csv(\"data/data3.csv\")\ndata3\ntable(data3$hometown) \n\ndata3 %&gt;% \n1  select(.,hometown) %&gt;%\n2  tbl_summary(.,\n              label = list(hometown ~ \"\"),\n              sort = list(everything() ~ \"frequency\")\n              ) %&gt;% \n  modify_header(label = \"\")\n\n\n\n1\n\nselect()でデータの中から出身地(hometown)を抜き出し\n\n2\n\ntbl_summary()でいい感じの表に\n\n\n\n\n\n\n  \n\n\n\n\n  京都   兵庫 北海道   大阪   奈良   島根   滋賀 \n     7      6      1     10      3      1      2 \n\n\n\n\n\n\n  \n    \n    \n      \n      N = 301\n    \n  \n  \n    \n\n        大阪\n10 (33%)\n        京都\n7 (23%)\n        兵庫\n6 (20%)\n        奈良\n3 (10%)\n        滋賀\n2 (6.7%)\n        北海道\n1 (3.3%)\n        島根\n1 (3.3%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "class/4_data.html#ヒストグラム",
    "href": "class/4_data.html#ヒストグラム",
    "title": "4 データを要約する",
    "section": "2.2 ヒストグラム",
    "text": "2.2 ヒストグラム\n特定のカテゴリごとの度数がわかるグラフです。例えばテストの点数なら，特定の範囲にどれぐらいの人がいるかがわかります。\n\n\nCode\ndata3 %$% \n  hist(test,\n1       breaks = seq(5,105,10),　\n2       xaxt = \"n\"　\n       ) \n3axis(1, at = 10*(0:100))　\n\n\n\n1\n\n10点ごとの幅に\n\n2\n\n自動生成されるラベルを非表示に\n\n3\n\nラベルの指定（０から100まで10刻みに）\n\n\n\n\n\n\n\nggplot2というパッケージ(tidyverseに同梱)を使うと以下のように作成できます。この程度の単純な表だとggplotの方がややこしいですが，いろいろカスタマイズするにはこちらの方が良いらしいです。\n\n\nCode\ndata3 %$%\n1  ggplot(., aes(test)) +\n2  geom_histogram(breaks = seq(5,105,10)) +\n3  scale_x_continuous(breaks=seq(0,100,10))\n\n\n\n1\n\nx軸の基準を指定\n\n2\n\nヒストグラムを作成（10点刻み）\n\n3\n\nラベルを作成(10点刻み)\n\n\n\n\n\n\n\n例えば，グループごとに色分けする\n\n\nCode\ndata3 %&lt;&gt;% mutate(class = as.factor(class))\n\ndata3 %&gt;%\n1  ggplot(., aes(test, fill = class)) +\n  geom_histogram(breaks = seq(5,105,10)) + \n  scale_x_continuous(breaks=seq(0,100,10))\n\n\n\n1\n\nfillで色分けしたいグループを指定\n\n\n\n\n\n\n\nクラスごとに分けて作成\n\n\nCode\ndata3 %$%\n  ggplot(., aes(test)) + \n  geom_histogram(breaks = seq(5,105,10)) + \n  scale_x_continuous(breaks=seq(0,100,10)) + \n1  facet_grid(~class)\n\n\n\n1\n\nclassごとに分けて表示\n\n\n\n\n\n\n\nこれだと，平均がどれも60点の3クラスだけど，得点のばらつき度合いが大きく違う，ということがわかりやすいです。"
  },
  {
    "objectID": "class/4_data.html#箱ひげ図",
    "href": "class/4_data.html#箱ひげ図",
    "title": "4 データを要約する",
    "section": "2.3 箱ひげ図",
    "text": "2.3 箱ひげ図\n複数のグループごとの中央値やばらつき度合いを視覚的に表現できます。ここでは，クラスごとのテストの点数の箱ひげ図を書きます。\n\n\nCode\ndata3 %$%\n1  boxplot(test~class)\n\n\n\n1\n\nboxplot()で箱ひげ図が書ける。()の中は(表示したい数値 ~ 場合分けしたいカテゴリ変数)\n\n\n\n\n\n\n\n\n最も外の線は最大値と最小値，箱の上下はそれぞれ75％点と25％点，つまり上下4分の1の点，真ん中の太線は中央値です。\nクラス2は全員が60点だったので，箱がなく中央値の線だけが記載されています（箱が潰れて線になっているイメージ）\n\n\n\nCode\npar(family= \"jp\")\ndata3 %$%\n  boxplot(test~gender)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2023_社会調査法",
    "section": "",
    "text": "2023年，立命館大学社会調査法の授業資料です。\n\n\n佐久間智広（さくまともひろ）\n神戸大学大学院経営学研究科・准教授\n授業のスケジュール"
  },
  {
    "objectID": "index.html#担当者",
    "href": "index.html#担当者",
    "title": "2023_社会調査法",
    "section": "",
    "text": "佐久間智広（さくまともひろ）\n神戸大学大学院経営学研究科・准教授\n授業のスケジュール"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "このサイトについて",
    "section": "",
    "text": "このサイトは，2023年度の立命館大学政策学部「社会調査法」用のサイトです"
  },
  {
    "objectID": "class/2_Rとは.html",
    "href": "class/2_Rとは.html",
    "title": "2 分析環境の構築",
    "section": "",
    "text": "Rは，統計分析に強みを持つコンピュータ言語です（統計ソフトと呼ぶこともあるけど，厳密な違いはよくわかりません）。\n\n\n\nエクセルでもある程度の分析はできますが，覚えさえすればエクセルよりもはるかに簡単です。また，エクセルでできる分析は限られていますが，Rではそれよりもはるかに高度なことができます。また，エクセルはそもそも表計算ソフトです。データが簡単にいじれてしまう（書き換えられてしまう）状態で分析作業をするのは好ましくありません。\nなんといってもフリーです。個人のコンピューター（職場が許すのであれば職場のコンピューターにも）にダウンロードすれば，卒業後も使えます。対してIBM社のSPSSは非常に高額です。研究者にでもならない限り個人で購入することはないでしょうし，職場で予算を取ることも難しいかもしれません。\n機械学習との絡みでPythonが流行ってきています。ただ，統計分析に関してはRに一日の長があるという印象です。Pythonはなんでも出来るけど，統計分析部分の操作性・拡張性はRの方が良さそう。\nコンピュータ言語のとっかかりはRでも，Rを使えるようになったらPythonもそこまで負担なく覚えられるでしょう。\n\n\n\n\nPosit社の提供する統合開発環境（IDE）。RはそれだけだとWindowsのconsoleとか，Macのterminalみたいな，コマンドだけの画面\n\nこれで使えないわけでもなけれど，もっと使いやすい方が良い。Rをもっと使いやすい状態にしてくれるアプリがRstudioです。\n\nRの画面（左下）\nRのプログラムを書くスペース（左上）\n読み込んだデータや，過去に実行したコマンドが見れるスペース（右上）\nパッケージやファイル，作った図表などがみれるスペース（右下）\n\n\n\nRstudioを使うと，分析結果レポートを文書やプレゼン用スライドに直接書き出すこともできます。\n\nいまこの資料もRstudioで書いています。\n\n文献リストの挿入などの機能も実装できるので，その気になればデータ分析から論文執筆まで全てRstudioでできます。\n\nGoogle colabなど，他の開発環境もありますが，インストールさえしてしまえば，Rstudioの方が便利だと思います。"
  },
  {
    "objectID": "class/2_Rとは.html#rとは",
    "href": "class/2_Rとは.html#rとは",
    "title": "2 分析環境の構築",
    "section": "",
    "text": "Rは，統計分析に強みを持つコンピュータ言語です（統計ソフトと呼ぶこともあるけど，厳密な違いはよくわかりません）。"
  },
  {
    "objectID": "class/2_Rとは.html#他のソフト方法との比較",
    "href": "class/2_Rとは.html#他のソフト方法との比較",
    "title": "2 分析環境の構築",
    "section": "",
    "text": "エクセルでもある程度の分析はできますが，覚えさえすればエクセルよりもはるかに簡単です。また，エクセルでできる分析は限られていますが，Rではそれよりもはるかに高度なことができます。また，エクセルはそもそも表計算ソフトです。データが簡単にいじれてしまう（書き換えられてしまう）状態で分析作業をするのは好ましくありません。\nなんといってもフリーです。個人のコンピューター（職場が許すのであれば職場のコンピューターにも）にダウンロードすれば，卒業後も使えます。対してIBM社のSPSSは非常に高額です。研究者にでもならない限り個人で購入することはないでしょうし，職場で予算を取ることも難しいかもしれません。\n機械学習との絡みでPythonが流行ってきています。ただ，統計分析に関してはRに一日の長があるという印象です。Pythonはなんでも出来るけど，統計分析部分の操作性・拡張性はRの方が良さそう。\nコンピュータ言語のとっかかりはRでも，Rを使えるようになったらPythonもそこまで負担なく覚えられるでしょう。"
  },
  {
    "objectID": "class/2_Rとは.html#rstudio",
    "href": "class/2_Rとは.html#rstudio",
    "title": "2 分析環境の構築",
    "section": "",
    "text": "Posit社の提供する統合開発環境（IDE）。RはそれだけだとWindowsのconsoleとか，Macのterminalみたいな，コマンドだけの画面\n\nこれで使えないわけでもなけれど，もっと使いやすい方が良い。Rをもっと使いやすい状態にしてくれるアプリがRstudioです。\n\nRの画面（左下）\nRのプログラムを書くスペース（左上）\n読み込んだデータや，過去に実行したコマンドが見れるスペース（右上）\nパッケージやファイル，作った図表などがみれるスペース（右下）\n\n\n\nRstudioを使うと，分析結果レポートを文書やプレゼン用スライドに直接書き出すこともできます。\n\nいまこの資料もRstudioで書いています。\n\n文献リストの挿入などの機能も実装できるので，その気になればデータ分析から論文執筆まで全てRstudioでできます。\n\nGoogle colabなど，他の開発環境もありますが，インストールさえしてしまえば，Rstudioの方が便利だと思います。"
  },
  {
    "objectID": "class/2_Rとは.html#rのインストール",
    "href": "class/2_Rとは.html#rのインストール",
    "title": "2 分析環境の構築",
    "section": "2.1 Rのインストール",
    "text": "2.1 Rのインストール\n\nR の公式サイトに行くhttps://cloud.r-project.org\n自分のOSに合ったものを選択\n\nWindowsなら Download R for Windows\n\nBase を選ぶ\n\nMacならDownload R for macOS\n\nSliconならR-X.X.X-arm64.pkg，IntelならR-X.X.X.pkg\n\n\nダウンロードしたものを実行してインストール"
  },
  {
    "objectID": "class/2_Rとは.html#rstudioのインストール",
    "href": "class/2_Rとは.html#rstudioのインストール",
    "title": "2 分析環境の構築",
    "section": "2.2 Rstudioのインストール",
    "text": "2.2 Rstudioのインストール\n\nRStudio の公式サイトに行くhttps://posit.co/products/open-source/rstudio/\n無料版（Open Source Edition）を選択\n自分のOSに合ったものを選んでダウンロード\nダウンロードしたものを実行してインストール\n\n\n\n\n\n\n\nX.X.X という部分はバージョン番号です。"
  },
  {
    "objectID": "class/2_Rとは.html#スクリプトファイル",
    "href": "class/2_Rとは.html#スクリプトファイル",
    "title": "2 分析環境の構築",
    "section": "3.1 スクリプトファイル",
    "text": "3.1 スクリプトファイル\nRなどの統計ソフトを使う利点の一つは，再現性です。例えばエクセルでは，どんな順番にどんな処理をしたのかは記録されません。Rなどのプログラミングソフトを使うと，操作した内容と順番をコードの形で記録しておけます。コードを記録したファイルを「スクリプトファイル」と言います。\nスクリプトファイルは，画面左上にある緑の「＋」アイコンを押して，「R Script」を選択することで新規作成できます。\n\nスクリプトファイルを作成すると（初期状態では）画面の左上に白紙のファイルが出てきます。ここにコマンドを打ち込んでいきます。例えば以下のコマンドを打つと，画面の左下にあるRの画面に実行結果が出ます。\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\n\n\n左下の画面（console）に直接 1+1 と打ち込んでも同じ結果が出ますが，後で記録に残らないので，コードはスクリプト画面に書く，左下は結果の表示だけ，と使い分けた方が良いです。"
  },
  {
    "objectID": "class/2_Rとは.html#課題",
    "href": "class/2_Rとは.html#課題",
    "title": "2 分析環境の構築",
    "section": "3.2 課題",
    "text": "3.2 課題\n\n3.2.1 算術演算子\nRスクリプトに以下の内容を打ち込んでください。スクリプト右上のRunボタンを押すか，Control + Enter (Macの場合は⌘+Enter)で実行してください。\n\n\nCode\n11+3\n22*4\n34-2\n44/2\n52^4\n6sqrt(16)\n\n\n\n1\n\n足し算( + )\n\n2\n\n掛け算( * )\n\n3\n\n引き算( - )\n\n4\n\n割り算 ( / )\n\n5\n\n累乗（ ^）\n\n6\n\nルート（ sqrt() )\n\n\n\n\n[1] 4\n[1] 8\n[1] 2\n[1] 2\n[1] 16\n[1] 4\n\n\n\n\n3.2.2 論理演算子\n論理演算子（&gt;, ==, != など）は，真（TRUE) か偽（FALSE）を返す。\n\n\nCode\n9 &gt; 9\n\n\n[1] FALSE\n\n\nCode\n9 &gt;= 9\n\n\n[1] TRUE\n\n\nCode\n'egg' == 'egg'\n\n\n[1] TRUE\n\n\nCode\n'apple' != 'apple'\n\n\n[1] FALSE"
  },
  {
    "objectID": "class/2_Rとは.html#オブジェクト",
    "href": "class/2_Rとは.html#オブジェクト",
    "title": "2 分析環境の構築",
    "section": "4.1 オブジェクト",
    "text": "4.1 オブジェクト\nRでは情報を自分で名前をつけたオブジェクトとして保存できます。Rstudioでは，保存されたオブジェクトは右上のEnvironmentと言うところに表示されます。\n\n\nCode\nx &lt;- 1\n\n\n「&lt;-」の左はオブジェクト，右はその中身を表します。なので，「xという名前のオブジェクトに1を入れる」という指示をしています。これを実行すると画面右上にxというオブジェクトが表示されるはずです。xの中身を確認するには，そのオブジェクトの名前（今回の場合x）を打つと良いです。\n\n\nCode\nx\n\n\n[1] 1\n\n\nこれを応用して変数を先に定義して，計算。\n\n\nCode\n#printで表示\nx &lt;- 3\ny &lt;- 5\nz &lt;- x * y\n1print(z)\n\n\n\n1\n\nz を表示するコマンド。ただし，print()を省略して単にzと打っても同じ。\n\n\n\n\n[1] 15\n\n\n文字列でもオブジェクトになります。\n\n\nCode\nuniv &lt;- \"Ritsumeikan University\"\nuniv\n\n\n[1] \"Ritsumeikan University\"\n\n\n\n\n\n\n\n\nTip\n\n\n\n変数名はあとで見返してもわかる名前をつけましょう。xとかaとかつけるとあとでわからなくなります。例えば英語と算数のテストの点があるなら，englishとmathと名付けるなど。\n\n\n複数の数値の並び（ベクトル）をオブジェクトとすることもできます。\n\n\nCode\nvec &lt;- c(1, 2, 3, 4, 5)\n\n\n縦×横の行列も作れます。matrixという名前です。ncol=2は列の数, byrow=TRUEは，横に並べるということ。\n\n\nCode\nmat &lt;- matrix(c(435,165,265,135), ncol=2, byrow=TRUE)\nmat\n\n\n     [,1] [,2]\n[1,]  435  165\n[2,]  265  135\n\n\n例えばbyrow=FALSE にすると縦に並ぶ\n\n\nCode\nmat2 &lt;- matrix(c(435,165,265,135), ncol=2, byrow=FALSE)\nmat2\n\n\n     [,1] [,2]\n[1,]  435  265\n[2,]  165  135\n\n\n縦横の名前をつけると\n\n\nCode\nrownames(mat) &lt;- c(\"行1\", \"行2\")\ncolnames(mat)&lt;- c(\"列1\", \"列2\")\nmat\n\n\n    列1 列2\n行1 435 165\n行2 265 135"
  },
  {
    "objectID": "class/2_Rとは.html#データフレーム",
    "href": "class/2_Rとは.html#データフレーム",
    "title": "2 分析環境の構築",
    "section": "4.2 データフレーム",
    "text": "4.2 データフレーム\nオブジェクトの中で重要な形式として，データフレームがあります。これは，縦方向に観測値を、横方向に変数を並べたデータを言います。\n\n\nCode\nage &lt;- c(18, 21, 22, 23, 34) #年齢のベクトル\ngender &lt;- c(\"female\", \"male\", \"male\", \"female\", \"female\")#性別のベクトル\ndframe &lt;- data.frame(age, gender)\ndframe\n\n\n\n\n  \n\n\n\nエクセル等のデータを読み込んで分析する場合は，このデータフレーム形式です。\nデータフレームの中の特定の行を指定する場合は，「データフレーム名$列名」\n\n\nCode\ndframe$gender\n\n\n[1] \"female\" \"male\"   \"male\"   \"female\" \"female\""
  },
  {
    "objectID": "class/2_Rとは.html#関数",
    "href": "class/2_Rとは.html#関数",
    "title": "2 分析環境の構築",
    "section": "4.3 関数",
    "text": "4.3 関数\nRを使う上で最も重要。何がしかの命令をすると，何かの結果が返ってくる。\n\n\nCode\n1mean(dframe$age)\n2min(dframe$age)\n3median(dframe$age)\n\n\n\n1\n\n平均はmean()\n\n2\n\n最小値（最大値）はmin() (max())\n\n3\n\n中央値はmedian()\n\n\n\n\n[1] 23.6\n[1] 18\n[1] 22\n\n\n上にあるように，Rのコマンドは基本的には，やること(実行する対象)という構造になっている。\n\nmean(dframe$age)は，\n\nやることが平均(mean)\n対象がデータフレームdframeのなかのage (dframe$age)"
  },
  {
    "objectID": "class/2_Rとは.html#プログラムの改行",
    "href": "class/2_Rとは.html#プログラムの改行",
    "title": "2 分析環境の構築",
    "section": "4.4 プログラムの改行",
    "text": "4.4 プログラムの改行\nRではかっこ()やコンマ（,）の後など，コードの切れ目で開業しても動作します。特に()何重にもなる場合，改行したほうが見やすいかもしれません。例えば，上でやった行列の作成コマンド\n\n\nCode\nmat &lt;- matrix(c(435,165,265,135), ncol=2, byrow=TRUE)\n\n\nは，以下のように書いても全く同じように動作します。\n\n\nCode\nmat &lt;- matrix(\n  c(435,165,265,135), \n  ncol=2, \n  byrow=TRUE\n  )\n\n\nこれでも同じですが，あまり改行しすぎるのもかえって読みにくいかもしれません。自分が見やすいように程よく改行してください。\n\n\nCode\nmat &lt;- \n  matrix(\n  c(\n    435,\n    165,\n    265,\n    135\n    ), \n  ncol=2, \n  byrow=TRUE\n  )"
  },
  {
    "objectID": "class/2_Rとは.html#パッケージ",
    "href": "class/2_Rとは.html#パッケージ",
    "title": "2 分析環境の構築",
    "section": "5.1 パッケージ",
    "text": "5.1 パッケージ\nRはそのままでもある程度のことができますが，より高度なことをしたり，同じことをより簡単にしたりするために追加の機能を足すことができます。この追加の機能はパッケージと言います。\n\n\n\n\n\n\nRがスマートフォンのOSのようなもので，パッケージはアプリのようなもの。iOSやAndroidは，そのままでも色々できるけれど，アプリを入れた方が便利。\n\n\n\n\nRのプログラムを格段にわかりやすくするパッケージであるtidyverseを使う準備をしてみます。パッケージは，最初に使う時にはインストールする必要があります（これは1回だけ。App Storeでアプリをとるような感じ）。\n\n\nCode\ninstall.packages(tidyverse)\n\n\nパッケージを使う時には，分析ファイルを実行する最初の段階で以下のコマンドを使います（スマートフォンにすでに入っているアプリを開くイメージ）。\n\n\nCode\nlibrary(tidyverse)\n\n\n後で使うので，以下のパッケージも読み込んでおきます。\n\n\nCode\nlibrary(magrittr)\nlibrary(googledrive)"
  },
  {
    "objectID": "class/2_Rとは.html#working-directoryの設定",
    "href": "class/2_Rとは.html#working-directoryの設定",
    "title": "2 分析環境の構築",
    "section": "5.2 Working Directoryの設定",
    "text": "5.2 Working Directoryの設定\n次に，Rが作業する場所（wd）を設定します。これは次で読み込むデータが保存されていたり，プログラムの中で生成したデータが保存されたりする場所です。\nパソコン上の場所をうまく指定できるのであれば，以下のようにコマンドを打てば良い です(下はMacでデスクトップをwdにした例)\n\n\nCode\nsetwd(\"~/Desktop\")\n\n\n場所の指定がうまくできない場合，Rstudio右下の箱の Filesタブから指定したいフォルダを選び，⚙マークから「Set As Working Directory」を選ぶことで，コマンドを実行してくれます (その後実行されたコマンドを自分のプログラムファイルにコピーしておくと次回以降便利)"
  },
  {
    "objectID": "class/2_Rとは.html#csvファイルの取り込み",
    "href": "class/2_Rとは.html#csvファイルの取り込み",
    "title": "2 分析環境の構築",
    "section": "6.1 csvファイルの取り込み",
    "text": "6.1 csvファイルの取り込み\nエクセルで列が変数，行が観測となるようにデータを作られていることを想定します。まず，これを表計算ソフト上でcsv形式で保存します。ここでは，さんプルデータとして下のような10人の生徒の4教科の科目のテストの点数を記録したファイルを作成しています。\n\n\n\n\n\n\nエクセル形式で保存されたファイルも読み込めますが，余計な情報が入っていないcsvファイルの方がトラブルが少ない？\n\n\n\n\nwdに入れたファイルを読み込むには，csv形式なら，read_csv(\"ファイル名\") もしくはread.csv(\"ファイル名\")を使います(ファイルがとても大きいとかでなかったらどっちを使ってもあまり変わりありません)。ここでは，tests.csvと言う名前のデータを，testsと言う名前で読み込んでいます。\n\n\nCode\ntests &lt;- read_csv(\"tests.csv\")\n\n\n読み込んだデータを見てみます。今回はいいけど，データが大きい場合など，たくさん表示されたら鬱陶しいなら最初のいくつかだけが表示されるhead(データ名)コマンドが便利です。\n\n\nCode\nhead(tests)"
  },
  {
    "objectID": "class/2_Rとは.html#google-driveに保存されたcsvファイルの読み込み",
    "href": "class/2_Rとは.html#google-driveに保存されたcsvファイルの読み込み",
    "title": "2 分析環境の構築",
    "section": "6.2 Google Driveに保存されたcsvファイルの読み込み",
    "text": "6.2 Google Driveに保存されたcsvファイルの読み込み\nデータをグループで共有するときなどに便利です。\n\ngoogle driveに保存したデータを共有（リンクを知っている人全員）に設定\nリンクurl（https://drive.google.com/file/d/*********/view?usp=sharing）の********の部分がidなので，その部分をメモしておく。\n下記の通り，idを定義して，下記の通りのコードを実行すると，目当てのファイルを取り込める。\n\n\n\nCode\nid = \"1x7426qSraIRdcbgW3a0F8vMF181Q_DHF\"\n\nz = read_csv(sprintf(\"https://docs.google.com/uc?id=%s&export=download\", id))"
  },
  {
    "objectID": "class/2_Rとは.html#dropboxに保存されたcsvファイルの読み込み",
    "href": "class/2_Rとは.html#dropboxに保存されたcsvファイルの読み込み",
    "title": "2 分析環境の構築",
    "section": "6.3 Dropboxに保存されたcsvファイルの読み込み",
    "text": "6.3 Dropboxに保存されたcsvファイルの読み込み\ngoogle driveと基本的に同じ\n\nDropbox上のファイルを共有，リンクを取得\nリンクの最後 dl=0をdl=1に変えて，read_csv (もしくは read.csv)コマンドで読み込めます\n\n\n\nCode\nz2 &lt;- read_csv(\"https://www.dropbox.com/s/6x344sfra54mcco/tests.csv?dl=1\")\n\n\nRows: 10 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): 出席番号, math, japanese, history, physics\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "class/2_Rとは.html#パイプ演算子",
    "href": "class/2_Rとは.html#パイプ演算子",
    "title": "2 分析環境の構築",
    "section": "7.1 パイプ演算子",
    "text": "7.1 パイプ演算子\ntidyverseとmagrittrパッケージのパイプ演算子を使うことで，同じコマンドをより読みやすくできます。これからは断りなくこれらのパッケージの機能を使います。\n\n7.1.1 例1\n読み込んだデータtestの算数(math)の平均点を求めたい。普通にやると [1.5.2 ][デ][ータフレーム]にあるように，データフレーム名$列名で指定するので\n\n\nCode\nmean(tests$math)\n\n\nパイプ演算子%$%を使うと同じコマンドが以下のようになる\n\n\nCode\ntests %$%\n  mean(math)\n\n\nこれだとあまり何がいいのかわかりませんが，複数の変数を指定したいときなど，いちいちデータフレーム名を指定しなくて良いので便利です。\n\n\n7.1.2 例2\n例1だと便利さを実感しにくいですが，例えば以下のコマンドだともう少し便利さがわかるかもしれません。以下は(1)testデータを使って，(2)数学の点数と他の点数の関係を分析(lm)した上で，(3)その結果を表示する(summary)もの。\n\n\nCode\nsummary(lm(math ~ japanese + physics ,data = tests))\n\n\n日本語の順番と，コマンドの構造が反対 (結果を表示する→分析内容→データ)\n全く同じことをパイプ演算子を使うと，(1) testデータで(2)分析をして(3)結果の要約を表示する，という思考の順番で書けます。\n\n\nCode\ntests %$%\n  lm(math ~ japanese + physics) %&gt;% \n  summary()\n\n\n命令が複雑になる程効果が実感できます。\nちなみに%$%は，使うデータを指定するのに使う。%&gt;%はコマンドの結果を次のコマンドに渡すのに使う。"
  },
  {
    "objectID": "class/2_Rとは.html#データの処理",
    "href": "class/2_Rとは.html#データの処理",
    "title": "2 分析環境の構築",
    "section": "7.2 データの処理",
    "text": "7.2 データの処理\n分析に入る前に必要そうな処理を紹介します。\n\n7.2.1 新しい変数の作成\n現在のデータにはない，4教科の合計点が欲しい。新しい変数はmutate()で作る。ただし，mutateだけだと，変数を作ってどこにも保存してくれないので，保存場所を指定する必要があります。今回は元のデータに付け足す形で作ります。\n\n\nCode\ntests &lt;- tests %&gt;% \n  mutate(sum = math + japanese + history + physics)\n\n\ntests に testsの中のデータを使って作った新しい変数を入れる。1行目が冗長なので，パイプ%&lt;&gt;%を使って書き直すと\n\n\nCode\ntests %&lt;&gt;%\n  mutate(sum = math + japanese + history + physics)\n\n\n以下も同じ\n\n\nCode\ntests %&lt;&gt;%\n  rowwise() %&gt;% \n  mutate(sum = sum(math, japanese, history, physics)) %&gt;% \n  ungroup()"
  },
  {
    "objectID": "class/11_en_ex.html",
    "href": "class/11_en_ex.html",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "",
    "text": "回帰分析において，説明変数が内生変数であると，推定された係数の値にバイアスが含まれる（結果がずれる）という問題が起こります。バイアスのせいで，本来関係ないものが関係あると推定されたり，その逆が起こったりするかもしれません。また，本来プラスの関係にあるものをマイナスに推定する，なども起こる可能性があります。\nこのような推定バイアスは，結果を用いた政策決定の判断を誤ったものにするリスクがあるという意味で深刻です。\n統計分析の多くはこの内生変数の問題に取り組むもの，とも解釈できます。今回は外生変数と内生変数がそれぞれ何か，内生変数の問題（内生性）がなぜ起こるのかを考えます。"
  },
  {
    "objectID": "class/11_en_ex.html#外生変数と内生変数",
    "href": "class/11_en_ex.html#外生変数と内生変数",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "",
    "text": "回帰分析において，説明変数が内生変数であると，推定された係数の値にバイアスが含まれる（結果がずれる）という問題が起こります。バイアスのせいで，本来関係ないものが関係あると推定されたり，その逆が起こったりするかもしれません。また，本来プラスの関係にあるものをマイナスに推定する，なども起こる可能性があります。\nこのような推定バイアスは，結果を用いた政策決定の判断を誤ったものにするリスクがあるという意味で深刻です。\n統計分析の多くはこの内生変数の問題に取り組むもの，とも解釈できます。今回は外生変数と内生変数がそれぞれ何か，内生変数の問題（内生性）がなぜ起こるのかを考えます。"
  },
  {
    "objectID": "class/11_en_ex.html#外生変数",
    "href": "class/11_en_ex.html#外生変数",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "2 外生変数",
    "text": "2 外生変数\n\\[\nY_i= \\beta_0 + \\beta_1 X_i + \\epsilon_i\n\\tag{1}\\]\nという単回帰分析を考えます（\\(E[\\epsilon_i] = 0\\)）。ここで，説明変数が外生変数であるとは，\\(X_i\\)と誤差項\\(\\epsilon_i\\)が相関しないことを意味しています。これは，\n\\[\n\\mathrm{E}[X_i\\epsilon_i]=\\mathrm{Cov}(X_i\\epsilon_i) = 0\n\\tag{2}\\]\nが成立することを意味し，この性質を外生性 (exogeneity)と言います。\nEquation 1 の両辺の期待値を取ると\n\\[\n\\begin{split}\n\\mathrm{E}[Y_i] &= \\beta_0 + \\beta_1 \\mathrm{E}[X_i] \\\\\n\\beta_0 &= \\mathrm{E}[Y_i] - \\beta_1 \\mathrm{E}[X_i]\n\\end{split}\n\\]\nとなり，これを Equation 1 に代入して\n\\[\n\\begin{split}\nY_i - \\mathrm{E}[Y_i] &=  \\beta_1 (X_i -\\mathrm{E}[X_i])\n\\end{split}\n\\tag{3}\\]\nとなります。ここで，両辺に\\(X_i\\)をかけて期待値をとったら\n\\[\n\\begin{split}\n\\mathrm{E}[X_i ( Y_i - \\mathrm{E}[Y_i]] &=\n\\beta_1\\mathrm{E}[X_i ( X_i - \\mathrm{E}[X_i]] +\n\\mathrm{Cov}(X_i\\epsilon_i) \\\\\n\\mathrm{Cov}(X_iY_i) &= \\beta_1\\mathrm{Var}(X_i)+ \\cancel{\\mathrm{Cov}(X_i\\epsilon_i)} \\\\\n\\beta_1 &=\\frac{\\mathrm{Cov}(X_iY_i) }{\\mathrm{Var}(X_i)}\n\\end{split}\n\\tag{4}\\]\nとなります。分散・共分散を標本分散・標本共分散に置き換えることで，実際のデータから\\(\\beta_1\\)を推定可能です。\nもし，調査者が要因\\(X_i\\)をランダムに決められる，自然科学の実験のような場合，\\(X_i\\)は外生変数になります。以下はサンプルデータToothGrowthです。「モルモットの歯の成長とビタミンCの摂取方法及び量の関係」について調べるためのデータです。\n\n\nCode\ntooth &lt;- ToothGrowth\ntooth\n\n\n\n\n  \n\n\n\nlenは歯の長さ(mm)，suppはビタミンCの摂取方法で，VCはビタミンCを直接与えたもの，OJはオレンジジュースを与えたものを表します。doseはビタミンCの量です。\n各個体に与えられるビタミンCの量はランダムに決定されます。ここで，ビタミンCの量が歯の長さとどのような関係にあるかを以下の回帰モデルで推定します。\n\\[\nlen = \\beta_o + \\beta_1dose+ \\epsilon\n\\]\n\n\nCode\noptions(scipen=100)\noptions(digits=5)\npacman::p_load(tidyverse, magrittr,modelsummary)\ntooth %$%\n  lm(len ~ dose) %&gt;% \n  summary\n\n\n\nCall:\nlm(formula = len ~ dose)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.450 -2.741 -0.745  2.834 10.114 \n\nCoefficients:\n            Estimate Std. Error t value          Pr(&gt;|t|)    \n(Intercept)    7.422      1.260    5.89 0.000000206421121 ***\ndose           9.764      0.953   10.25 0.000000000000012 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.6 on 58 degrees of freedom\nMultiple R-squared:  0.644, Adjusted R-squared:  0.638 \nF-statistic:  105 on 1 and 58 DF,  p-value: 0.0000000000000123\n\n\n係数は9.76，有意水準は0.1%以下で有意(***)です。"
  },
  {
    "objectID": "class/11_en_ex.html#内生変数",
    "href": "class/11_en_ex.html#内生変数",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "3 内生変数",
    "text": "3 内生変数\nもし， Equation 1 の\\(X_i\\)が外生変数ではない，つまり\\(\\epsilon_i\\)と相関しているとする\n\\[\n\\mathrm{E}[X_i\\epsilon_i]=\\mathrm{Cov}(X_i\\epsilon_i) \\not= 0\n\\tag{5}\\]\nこの時，\\(X_i\\)は内生性(endogeneity)を持つ内生変数と言います。この時 Equation 4 において，\\(\\mathrm{Cov}(X_i\\epsilon_i)\\)が消えないので\n\\[\n\\begin{split}\n\\beta_1 + \\frac{\\mathrm{Cov}(X_i\\epsilon_i)}{\\mathrm{Var}(X_i)}\n&=\\frac{\\mathrm{Cov}(X_iY_i) }{\\mathrm{Var}(X_i)}\n\\end{split}\n\\]\nとなり，\\(\\mathrm{Cov}(X_i\\epsilon_i) / \\mathrm{Var}(X_i)\\)分推定値がズレる（バイアスがかかる）ことになります。\n\n\nCode\n1n &lt;- 200\n2e &lt;- rnorm(n)\n3X &lt;- (1 + 0.4*e) *　runif(n)\n4b0 &lt;- 1\n5b1 &lt;- 2\n6Y &lt;- b0 + X * b1 + e\n\n\n\n1\n\nサンプルサイズ200\n\n2\n\n誤差項。標準正規分布\\(\\mathrm{N}(0,1)\\)に従う変数をn個作成\n\n3\n\n説明変数X。誤差項eと相関するように作られている。runif() は，[0,1]の一様分布を作成する関数。\n\n4\n\n真の切片は1\n\n5\n\n真の係数は2\n\n6\n\nYはXの単回帰分析の結果となるように設定。\n\n\n\n\nこれらを使って回帰分析を行う\n\n\nCode\nlm(Y~X) |&gt;\n  summary()\n\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.2747 -0.5082 -0.0456  0.4720  3.1169 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)   0.2146     0.0965    2.22               0.027 *  \nX             3.5019     0.1535   22.81 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.82 on 198 degrees of freedom\nMultiple R-squared:  0.724, Adjusted R-squared:  0.723 \nF-statistic:  520 on 1 and 198 DF,  p-value: &lt;0.0000000000000002\n\n\n切片の値は真の値1より小さく，計数の値は真の値2より大きく誤推定されている。これは，説明変数と誤差項の相関が引き起こしていて，それらの相関が正だから計数がより大きく推定されている。"
  },
  {
    "objectID": "class/11_en_ex.html#内生変数の生じる理由",
    "href": "class/11_en_ex.html#内生変数の生じる理由",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "4 内生変数の生じる理由",
    "text": "4 内生変数の生じる理由\n\n4.1 欠落変数\nもし，真のモデルが\n\\[\nY_i= \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_i\n\\tag{6}\\]\nで，\\(X_1\\)と\\(X_2\\)がともに共に誤差項と相関しないとします。この場合，重回帰分析を行うことで，\\(X_1\\)と\\(X_2\\)が\\(Y_i\\)に与える影響を正しく推定できます。\nここで，\\(X_2\\)が得られない場合を考えます。推定に使えるのは\\(X_1\\)だけなので\n\\[\nY_i= \\gamma_0 + \\gamma_1 X_i + \\eta_i\n\\tag{7}\\]\nを推定することになります。この際には，\n\\[\nE(\\gamma_1)=\\beta_1+\\beta_2\\frac{\\mathrm{Cov}({X_1X_2})}{\\mathrm{Var}({X_1})}\n\\tag{8}\\]\nとなり，\\(\\beta_2\\mathrm{Cov}({X_1X_2})/\\mathrm{Var}({X_1})\\)分のバイアスがかかります。このバイアスは，\\(\\mathrm{Cov}({X_1X_2})=0\\)でない限り存在します1。これは，疑似相関の際に起こるバイアスを表しています。\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 測定誤差\n社会調査で多く用いられる「アンケート調査」のデータは，本来測定したいものを正確に測定できていない可能性があります（アンケート調査に適当に回答した経験はありませんか？）\nもし，測定したいものの測定に誤差があった場合，本来は， Equation 1 式\n\\[\nY_i= \\beta_0 + \\beta_1 X_i + \\epsilon_i\n\\]\nを検証したいのに，Xが誤差のあるWでしか測定しかできないとします。\n\\[\nW_i = X_i + u_i\n\\]\nそうすると， Equation 1 式は\n\\[\nY_i= \\beta_0 + \\beta_1 W_i + \\eta_i\n\\tag{9}\\]\nとなります。ここで，\n\\[\n\\eta_i = \\epsilon_i - \\beta_1u_i\n\\]\nとなります。\\(u_i\\)の期待値は0で\\(X_i,\\epsilon_i\\)と独立と仮定します。外生性の条件である\\(\\mathrm{E}[W_i\\eta_i]\\)は\n\\[\n\\begin{split}\n\\mathrm{E}[W_i\\eta_i] &= \\mathrm{E}[W_i(\\epsilon_i - \\beta_1u_i)] \\\\\n&=  \\mathrm{E}[W_i\\epsilon_i] - \\beta_1 \\mathrm{E}[W_iu_i] \\\\\n&=\\mathrm{E}[(X_i+u_i) \\epsilon_i] - \\beta_1 \\mathrm{E}[(X_i+u_i)u_i] \\\\\n&= - \\beta_1 \\mathrm{Var}(u_i)\n\\end{split}\n\\]\nとなるので，\\(\\beta_1 \\not= 0\\)である限り0ではない，つまり外生性が満たされなくなります。\n実際，\\(\\beta_1\\) の推定値は，\n\\[\n\\frac{\\mathrm{Cov}(W_iY_i)}{\\mathrm{Var}(W_i)}= \\beta_1 \\left( \\frac{\\mathrm{Var}(X_i)}{\\mathrm{Var}(X_i) + \\mathrm{Var}(u_i)} \\right)\n\\]\nとなります。\n\\[\n0&lt;\\left( \\frac{\\mathrm{Var}(X_i)}{\\mathrm{Var}(X_i) + \\mathrm{Var}(u_i)} \\right)&lt;1\n\\]\nなので，\\(\\beta_1 &gt; 0\\)の時\n\\[\n\\beta_1 &gt; \\beta_1\\left( \\frac{\\mathrm{Var}(X_i)}{\\mathrm{Var}(X_i) + \\mathrm{Var}(u_i)} \\right)&gt;0\n\\]\nとなるため，\\(\\beta_1\\)は過小推定されます。この推定のずれは，\\(\\mathrm{Var}(u_i)\\)が大きければ大きいほど強くなります（より過小に推定されます）。\n\n\nCode\nn &lt;- 200 \n1e &lt;- rnorm(n)\nX &lt;- rnorm(n) \n2u &lt;- runif(n,-1,1)\nW &lt;- X + u\nb0 &lt;- 1\nb1 &lt;- 2\n3Y &lt;- b0 + X * b1 +e\n\n\n\n1\n\n誤差項\n\n2\n\n測定誤差 [-1,1]の値をとる一様分布に従う期待値0の値\n\n3\n\nYとXの関係\n\n\n\n\n\n\nCode\nlm(Y~W)|&gt;\n  summary()\n\n\n\nCall:\nlm(formula = Y ~ W)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.687 -0.826  0.094  0.838  3.568 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept)   0.9586     0.0971    9.87 &lt;0.0000000000000002 ***\nW             1.4457     0.0863   16.75 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.37 on 198 degrees of freedom\nMultiple R-squared:  0.586, Adjusted R-squared:  0.584 \nF-statistic:  281 on 1 and 198 DF,  p-value: &lt;0.0000000000000002\n\n\n真の関係よりも過小に評価されるはずです。\n\n\n4.3 同時性\n同時性は，従属変数と独立変数が，相互に依存している場合に起きます。\nある地域の警察官と犯罪件数との関係です。\n地域\\(i\\)の警察官の数を\\(X_i\\)，犯罪件数を\\(Y_i\\)とします。警察官の数を増やすと犯罪件数がどの程度減少するかを調べるならば， Equation 1 のように，YをXに回帰すれば良さそうです。しかし，警察官を配置すると犯罪は減少しそうですが，犯罪が多い地域に重点的に配置されそうです。つまり\n\\[\n\\left\\{ \\,\n    \\begin{aligned}\n    & Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i \\\\\n    & X_i = \\gamma_0 + \\gamma_1 Y_i + u_i\n    \\end{aligned}\n\\right.\n\\tag{10}\\]\nただし，\\(\\epsilon_i, u_i\\)は相関しないものとします。ここで，上の式の外生性を確認すると\n\\[\n\\begin{split}\n\\mathrm{E}[X_i\\epsilon_i] &= \\mathrm{E}[ (\\gamma_0 + \\gamma_1 X_i + u_i)\\epsilon_i]  \\\\\n&=\\mathrm{E}[Y_i\\epsilon_i]\\gamma_1\n\\end{split}\n\\]\nとなり\\(\\gamma_1 \\not=0\\)となる限り0にはならず外生性は満たされません。"
  },
  {
    "objectID": "class/11_en_ex.html#内生性を見抜くためには",
    "href": "class/11_en_ex.html#内生性を見抜くためには",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "5 内生性を見抜くためには？",
    "text": "5 内生性を見抜くためには？\n内生性を，データ分析の結果だけから見抜くことは無理（内生性の検定はあるけれど…）\nそれよりも重要なのは分析対象の知識。データだけを見て（分析対象の知識がないまま）うまく分析することはできない。"
  },
  {
    "objectID": "class/11_en_ex.html#内生性の強さとバイアスの大きさ",
    "href": "class/11_en_ex.html#内生性の強さとバイアスの大きさ",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "6 内生性の強さとバイアスの大きさ",
    "text": "6 内生性の強さとバイアスの大きさ\n\n\nCode\nn &lt;- 200 \nb0 &lt;- 1\nb1 &lt;- 2\nEstimate &lt;- \\(lambda){\n  e &lt;- rnorm(n)\n  X &lt;- (1 + lambda * e ) * runif(n)\n  Y &lt;- b0 + X * b1 + e\n  lm(Y~X)$coefficient\n}\n\n\nsimulate &lt;- \\(lambda){\n  estimates &lt;- matrix(0,100,2)\n  for(i in 1:100) estimates[i, ] &lt;-Estimate(lambda)\n  colMeans(estimates)\n}\n\nlambdas &lt;-(0:60) / 100\nresults &lt;- mapply(simulate, lambdas)\n\nbias0 &lt;-results[1, ] -b0\nbias1 &lt;-results[2, ] -b1\n\n#par(family= 'Hiragino Sans')\n#plot(lambdas, bias0, xlab='λ', ylab = 'バイアス')\n#plot(lambdas, bias1, xlab='λ', ylab = 'バイアス')\n\n\na &lt;- tibble(lambdas,bias0,bias1)\nggplot(a,\n       aes(x = lambdas,\n           y = bias0)\n       ) + \n  geom_point()+\n  theme(text = element_text(family = 'Hiragino Sans')) +\n  labs(title= \"切片のバイアス\",\n       x = 'λ',\n       y = 'バイアス')\n\n\n\n\n\nCode\nggplot(a,\n       aes(x = lambdas,\n           y = bias1)\n       ) + \n  geom_point()+\n  theme(text = element_text(family = 'Hiragino Sans')) +\n  labs(title= \"係数のバイアス\",\n       x = 'λ',\n       y = 'バイアス')"
  },
  {
    "objectID": "class/11_en_ex.html#参考-内生変数の問題",
    "href": "class/11_en_ex.html#参考-内生変数の問題",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "7 参考: 内生変数の問題",
    "text": "7 参考: 内生変数の問題\n\n7.1 前提条件\nYに対するAの効果を知りたい\n\\[\nY_i = \\beta_0+\\beta_1A_i+u_i\n\\]\n最小二乗法*を使って推定する。\n\\[\n\\hat{\\beta}_1=\\sum\\frac{(A_i-\\bar{A})Y_i}{(A_i-\\bar A)^2}=\\frac{S_{AY}}{S_{AA}}\n\\]\n\\[\n\\hat{\\beta_0}=\\bar{Y}-\\hat{\\beta_1}\\bar{A}\n\\]\nただし\n\\(\\bar{A}=\\frac{1}{n}\\sum A_i\\)\nuに関する仮定\n\\(E[u_i]=0\\)\n\\(V(u_i)=\\sigma^2\\)\nここで，Aと Yの関係が歪みなく推定されるためには\n\\(E[u|A]=0\\)\n(Yと関係するA以外の要因が，Aと関係ない) 時\n真のモデルは\n\\[\nY_i=\\beta_0+\\beta_1A_i+\\beta_2L_i+u_i\n\\]\nでも，推定するモデルは\n\\[\nY_i=\\alpha_0+\\alpha_1A_i+v_i\n\\]\nつまり，実際には含まれるべきLが含まれていない。どうなる？\n\n\n7.2 解いてみる\n推定するモデルの推定値に真のモデルを代入すると\n\\[\n\\begin{split}\\hat\\alpha_1&=\\frac{S_{AY}}{S_{AA}} = \\frac{\\sum (A_i-\\bar A)(Y_i-\\bar Y)}{ \\sum (A_i-\\bar A)^2}\\\\&=\\sum w_{Ai}Y_i \\\\&=\\sum w_{Ai}(\\beta_0+\\beta_1A_i+\\beta_2L_i+u_i)\\\\&=\\beta_1+\\beta_2\\frac{S_{AL}}{S_{AA}}+\\sum w_{2i}u_i\\end{split}\n\\]\n期待値を取ると\n\\[\nE(\\alpha_1)=\\beta_1+\\beta_2\\frac{S_{AL}}{S_{AA}}\n\\]\n\\(\\beta_2\\frac{S_{AL}}{S_{AA}}\\)の部分がLを入れなかったことによって生じる推定値のずれ（バイアス）2\n\\(S_{AL}=0\\)でない限り不偏性が保たれないので，間違った推定値が計算される。一致性もない。"
  },
  {
    "objectID": "class/11_en_ex.html#footnotes",
    "href": "class/11_en_ex.html#footnotes",
    "title": "11 内省変数・外生変数と因果推論",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n推定するモデル Equation 7 に，正しいモデルを代入すると，\n\\[\n\\begin{split}\\hat\\gamma_1&=\\frac{S_{X_1Y}}{S_{X_1X_1}} = \\frac{\\sum (X_{1i}-\\bar X_{1})(Y_i-\\bar Y)}{ \\sum (X_{1i}-\\bar X_1)^2}\\\\&=\\sum w_{X_{1i}}Y_i \\\\&=\\sum w_{X_{1i}}(\\beta_0+\\beta_1X_{1i}+\\beta_2X_{2i}+\\epsilon_i)\\\\&=\\beta_1+\\beta_2\\frac{S_{X_1X_2}}{S_{X_1X_1}}+\\sum w_{X_{1i}}\\epsilon_i\\end{split}\n\\]\nこれの期待値を取ると，上の式 Equation 8 になります。ただし，\n\n\\(S_{X_{1}Y} = \\mathrm{Cov}(X_{1i}Y_i)=\\sum (X_{1i}-\\bar X)(Y_i-\\bar Y)\\)\n\\(S_{X_iX_i} = \\mathrm{Var}(X_1) = \\sum (X_{1i}-\\bar X)^2\\)\n\\(w_{X_{1i}}=({X_{1i} - \\bar X) / \\sum(X_{1i}- \\bar X)}\\)\n\n↩︎\n\n\\(S_{AY} = \\sum (A_i-\\bar A)(Y_i-\\bar Y)\\)\n\\(S_{AA} = \\sum (A_i-\\bar A)^2\\)\n\\(w_{Ai}=\\frac{A_i - \\bar A}{\\sum(A_i - \\bar A)}\\)\n\n↩︎"
  },
  {
    "objectID": "class/6_hyohon.html",
    "href": "class/6_hyohon.html",
    "title": "6 母集団と標本",
    "section": "",
    "text": "社会調査や学術研究では，知りたい対象と手元のデータが必ずしも一致していません。そもそも，知りたい対象全体のデータを取るような調査はほとんど行われません。\n\n唯一の例外は国勢調査\n\n例えば，世論調査は日本在住者の政治に対する意見などを知るためにデータを集めますが，全国民を対象としているわけではありません。\n\n全国民の意見を聞いていたら時間もお金もかかります。そもそも全員と連絡をつけることは非現実的です。\nそこで，例えば1,000人に聞いた意見から日本全体の世論を推測します。\n\n例えば，新しい薬の効果を検証したい場合，知りたい対象は，過去・現在・未来に渡る特定の病気の患者への効果です。調査時点で過去の患者や未来の患者に対する効果を知ることはできません。\n\nそこで，治験対象者のデータから，人類一般に対する効果を推測します。\n\nここで，知りたい対象を母集団，検証に使う母集団の一部を標本と言います。\n\n\n\n\n\n\n\n\nNote\n\n\n\n特に経済学などでは，上記1つ目の例のように日本人全体，といった特定の母集団を想定しないことが多いとされます(星野ほか 2023; 高橋 2022)。その代わりに，サンプルを生み出す特定の確率分布を母集団と呼びます。\n\n\n\n確率論を基礎として，十分な数の適切に選ばれた標本を適切な方法で分析すると，非常に高い精度で母集団の傾向を推測できることが知られています。\n\n適切な方法の基本は，ランダムサンプリング（無作為抽出）\n逆に，うまくサンプルを取らなかったら当然ズレます\n\n例：東京大学の学生の1,000人のTOEICの点数の平均を使って，日本国民の英語力を推定する。\n\nこの場合，母集団は東京大学の学生？\n\n\n\n\nただし，「適切に標本を選ぶこと」「適切に分析すること」は現実にそう簡単ではなく，それゆえこの授業で扱う多変量解析を含め，多くの統計理論が研究され続けています。\n\nまずは，理想的な状況における推測について扱います。"
  },
  {
    "objectID": "class/6_hyohon.html#大数の法則のシミュレーション",
    "href": "class/6_hyohon.html#大数の法則のシミュレーション",
    "title": "6 母集団と標本",
    "section": "3.1 大数の法則のシミュレーション",
    "text": "3.1 大数の法則のシミュレーション\nサイコロには１から6までの目があり，それぞれが出る確率は1/6です。したがって，母集団の平均は，\n\\[\n\\frac{1}{6}\\Sigma^6_{i=1}i=\\frac{21}{6}=3.5\n\\]\nサイコロを10回降った時\n\n\nCode\ns10 &lt;- sample(1:6,10,replace = TRUE)\nmean(s10)\n\n\n[1] 3.6\n\n\n1行目の sample()は，決められた数の標本を無作為に選び出す関数です。ここでは，1から6までの数を無作為に10個選び出しています。replaceは復元抽出をするかしないかを指定するオプションです。「１から6までの数を無作為に10個復元抽出で選び取る」という命令をしていることになり，これをs10と名づけて保存しています。\n2行目は，このs10の平均を計算しています。\n同じように，1,000回サイコロを振ることを以下のように再現してみます。\n\n\nCode\ns1000 &lt;- sample(1:6,1000,replace = TRUE)\nmean(s1000)\n\n\n[1] 3.559\n\n\n（無作為抽出しているので，結果は個々人で違うと思いますが）おそらく10回の時よりも1,000回の時の方が期待値である3.5に近いはずです。\nこれをさらに以下のように検討してみます。\n\n\nCode\n#サイコロを10回振るのを1000回繰り返す\nS &lt;- 1000\nrec10 &lt;- numeric(S)\n\nfor(i in 1:S){\n  rec10[i] &lt;- sample(1:6, 10, replace = TRUE)|&gt;\n    mean()\n  }\n\nsummary(rec10)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.900   3.100   3.500   3.493   3.900   5.200 \n\n\n\n1行目は，Sという名前で数字の1000を保存しています。\n2行目は，numericというコマンドで空（0）の行をSの数だけ作って，rec10と名付けています。\n3行目は，1から6までの数字を無作為に10個（サイコロを10回振る）時の平均を計算して，rec10のi行目に入れる，という作業をS回(1000行分)繰り返しています。\n4行目は，そうして作られたrec10の最小値，最大値，平均，中央値等を出しています。\n\n\n\nCode\nhist(rec10)\n\n\n\n\n\n(毎回結果は変わりますが)この時最小値は1.8，最大値は5.3，平均は3.482でした。\nこれをサイコロを10000回振るのを1000回繰り返すのに変えてみます。\n\n\nCode\n#サイコロを10000回振るのを1000回繰り返す\nS &lt;- 1000\nrec10000 &lt;- numeric(S)\n\nfor(i in 1:S){\n  rec10000[i] &lt;- sample(1:6, 10000, replace = TRUE)|&gt;\n    mean()\n  }\n\nsummary(rec10000)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.435   3.489   3.501   3.500   3.512   3.553 \n\n\nすると，最小値3.450，最大値3.553，平均値3.449と，3.5にかなり収束しました。\n\n\nCode\n#サイコロを100回振るのを1000回繰り返す\nS &lt;- 1000\nrec100 &lt;- numeric(S)\n\nfor(i in 1:S){\n  rec100[i] &lt;- sample(1:6, 100, replace = TRUE)|&gt;\n    mean()\n  }\n\n# 3つそれぞれヒストグラムを書いて，\n#一つのシートに重ねて表示\nhist(rec10000, \n     col=\"#FF00007F\", \n     xlim=c(1.5,5),\n     ann=F, \n     main=\"\", \n     xlab=\"\" ,\n     breaks=seq(1,6,0.1)\n     )\n\npar(new=T)\nhist(rec10, \n     breaks=seq(1,6,0.1),\n     col=\"#0000FF7F\",\n     ann=F, \n     add=T)\nhist(rec100, \n     breaks=seq(1,6,0.1),\n     col=\"#32CD32\",\n     ann=F, \n     add=T)\n\nlegend(\"topright\", \n       legend=c(\"rec10000\", \n                \"rec10\", \n                \"rec100\"),\n       fill=c(\"#FF00007F\", \n              \"#0000FF7F\",\n              \"#32CD32\")\n       )\n\n\n\n\n\nサンプルサイズ100のものも加えてヒストグラムを書きました。一回一回のサンプルサイズが大きいほど，母平均に近い値を取っていることが見えます。"
  },
  {
    "objectID": "class/6_hyohon.html#footnotes",
    "href": "class/6_hyohon.html#footnotes",
    "title": "6 母集団と標本",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n母数\\(\\theta\\)の推定量を\\(\\hat \\theta_n\\)とする。任意の\\(\\epsilon&gt;0\\)に対して\n\\[\n\\lim_{n\\to \\infty}Pr\\{|\\hat{\\theta}_n-\\theta|&gt;\\epsilon\\}=0\n\\]が成立するとき，推定量\\(\\hat \\theta_n\\)を一致推定量(consisent estimator)という。これは\n\n推定量\\(\\hat \\theta_n\\)の期待値が\\(\\theta\\)に確率収束すること(￼\\(\\lim_{n\\to \\infty}E[\\hat{\\theta}_n]=\\theta\\))\n分散が0に確率収束すること(\\(\\lim_{n\\to \\infty}V[\\hat{\\theta}_n]=0\\))\n\nとも言い換えられる。↩︎"
  },
  {
    "objectID": "class/9_multiple_reg.html",
    "href": "class/9_multiple_reg.html",
    "title": "9 重回帰分析",
    "section": "",
    "text": "1 前回やったこと：回帰分析"
  },
  {
    "objectID": "class/7_kentei.html",
    "href": "class/7_kentei.html",
    "title": "7 検定",
    "section": "",
    "text": "Code\n1rm(list=ls()); gc();  gc();\n2if (!require(\"pacman\")) install.packages(\"pacman\")\n3pacman::p_load(tidyverse, magrittr,estimatr,car,modelsummary,ggrepel,patchwork)\n\n\n\n1\n\n前の作業など，rのメモリに入っているものをリセットするコマンド\n\n2\n\nパッケージ管理用のパッケージであるpacmanが入っていない場合はインストール\n\n3\n\n複数のパッケージを一度に呼び出す"
  },
  {
    "objectID": "class/7_kentei.html#コイン投げのシミュレーション",
    "href": "class/7_kentei.html#コイン投げのシミュレーション",
    "title": "7 検定",
    "section": "2.1 コイン投げのシミュレーション",
    "text": "2.1 コイン投げのシミュレーション\n\n有意水準は（経済学や経営学では）5％や10％あたりが用いられます。5％としてみます。\n帰無仮説を設定する。コインを投げて表になる確率を\\(p\\) とすると，帰無仮説\\(H_0\\)は \\(p = \\frac{1}{2}\\)，対立仮説\\(H_1\\)は \\(p \\ne \\frac{1}{2}\\)と設定。\nコインを100回投げる。結果が表65，裏35だとする\n帰無仮説が正しいとして，100回中おもてが60-40回に収まる確率を計算してみる\n\n\n\nCode\n1p40 &lt;- pbinom(q = 40, size = 100, prob = 0.5)\n2p60 &lt;- pbinom(q = 60, size = 100, prob = 0.5)\np60-p40\n\n\n\n1\n\n表が40回以下の確率\n\n2\n\n表が60回以下の確率\n\n\n\n\n[1] 0.9539559\n\n\nこの0.9539は，コインを100回投げて，60回から40回表が出る確率を表しています。95％以上の確率で60-40会表が出る，逆に65回は5％以下と解釈できます。事前に設定された有意水準5％を下回るので，帰無仮説は棄却され，対立仮説である\\(H_1\\)の\\(p \\ne \\frac{1}{2}\\)が採択されます。"
  },
  {
    "objectID": "class/7_kentei.html#回帰分析と統計的仮説検定",
    "href": "class/7_kentei.html#回帰分析と統計的仮説検定",
    "title": "7 検定",
    "section": "2.2 回帰分析と統計的仮説検定",
    "text": "2.2 回帰分析と統計的仮説検定\n\n回帰分析についても同じ考え方で検定をします。\n一般的には，説明変数が従属変数と関係ない，つまり係数\\(\\beta = 0\\) を帰無仮説として検定します。"
  },
  {
    "objectID": "class/7_kentei.html#正規分布nmu1の場合",
    "href": "class/7_kentei.html#正規分布nmu1の場合",
    "title": "7 検定",
    "section": "3.1 正規分布\\(N(\\mu,1)\\)の場合",
    "text": "3.1 正規分布\\(N(\\mu,1)\\)の場合\n母集団の分布が平均\\(\\mu\\)標準偏差1と判明しているケース\n\n有意水準は，5％とします。\n帰無仮説\\(H_0 : \\mu = 0\\)とすると対立仮説\\(H_1 : \\mu \\ne 0\\)となります。\n検定の対象の母集団から標本を抽出します。これは大きいほうが望ましいです。ここから平均値を計算します。\nもし帰無仮説が正しいのであれば，母集団は\\(N(0,1)\\)つまり標準正規分布であるはずです。標準正規分布に従う確率変数について，\\(|X|&gt;1.96\\)となる確率が（有意水準である）5％であることが知られています。つまり，平均値の絶対値が1.96より小さかったら帰無仮説を採択，大きかったら帰無仮説を棄却して，対立仮説をとる，ということです。"
  },
  {
    "objectID": "class/7_kentei.html#t検定",
    "href": "class/7_kentei.html#t検定",
    "title": "7 検定",
    "section": "3.2 t検定",
    "text": "3.2 t検定\n母集団の分布があらかじめわかっているということは基本的にはありません。しかし，母集団の分布がわからないという条件でも上のような検定が行える場合があります。\n\n有意水準は，5％とします。\n帰無仮説\\(H_0 : \\mu = 0\\)とすると対立仮説\\(H_1 : \\mu \\ne 0\\)となります。\n検定の対象の母集団から大きさnの標本を抽出します。もし，nが十分に大きいと，中心極限定理によって，以下の\\(Z_n\\)は近似的に標準正規分布\\(N(0,1)\\)に従います。\n\\[\nZ_n = \\frac{\\sqrt{n}(\\bar{X_n} - \\mu)}{\\sqrt{V_n}}\n\\]\nただし，\\(\\bar{X_n}\\)は標本平均，\\(V_n\\)は標本分散です。\nもし帰無仮説が正しいのであれば，\\(\\mu = 0\\)なので，\\(Z_n\\)は\n\\[\nt_n = \\frac{\\sqrt{n}\\bar{X_n}}{\\sqrt{V_n}}\n\\]\nと書き換えることができて，これが標準正規分布\\(N(0,1)\\)に従います。\n標準正規分布に従う確率変数について，\\(|X|&gt;1.96\\)となる確率が（有意水準である）5％であることが知られています。つまり，平均値の絶対値が1.96より小さかったら帰無仮説を採択，大きかったら帰無仮説を棄却して，対立仮説をとる，ということです。\n\n上記\\(t_n\\)をt値，これを用いた検定をt検定と言います。"
  },
  {
    "objectID": "class/7_kentei.html#p値",
    "href": "class/7_kentei.html#p値",
    "title": "7 検定",
    "section": "3.3 p値",
    "text": "3.3 p値\n上のt検定ではあらかじめ5％とか有意水準を決めていました。しかし，t値に対応させる形で，tの値がある数の時，その数字で帰無仮説を棄却するには有意水準をどこまで大きくする必要があるのか，という確率を直接求めることもできます。それをp値と言います。\nt検定において，t値を見るのと，p値を見るのは本質的には同義です。p値5％がt値1.96を表しています。"
  },
  {
    "objectID": "class/7_kentei.html#信頼区間の導出",
    "href": "class/7_kentei.html#信頼区間の導出",
    "title": "7 検定",
    "section": "4.1 信頼区間の導出",
    "text": "4.1 信頼区間の導出\n\nサンプルが母集団からの無作為抽出であるという前提のもと，標準誤差（se）を計算する\n\n± se × 1.96 で計算する。\n\nテキストの事例では，信頼区間は0.27から0.81\n詳しくは次のページ"
  },
  {
    "objectID": "class/7_kentei.html#信頼区間の意味",
    "href": "class/7_kentei.html#信頼区間の意味",
    "title": "7 検定",
    "section": "4.2 信頼区間の意味",
    "text": "4.2 信頼区間の意味\n\n母集団からのサンプリングを繰り返し行った場合，95％はこの範囲の中に入る。\n95％真のパラメータがこの範囲の中に入っている。\n特定の研究における95%信頼区間は，「95％の確率でestimand（母集団のパラメータ）がこの範囲の中に入る」ということを意味しているわけではない。\n\nestimandは固定された値（確率変数ではない）だから。\n\n信頼区間は，頻度論的な解釈しか与えない。\n\n信頼区間の数値(95%)は，複数の研究（もしくは仮想上の研究の繰り返し）において，未知の母集団の数値が入る頻度を表している。\n\n三重大学奥村先生の説明が丁寧"
  },
  {
    "objectID": "class/7_kentei.html#練習問題",
    "href": "class/7_kentei.html#練習問題",
    "title": "7 検定",
    "section": "6.1 練習問題",
    "text": "6.1 練習問題\n\n\nCode\n1rm(list=ls()); gc();  gc();\n2if (!require(\"pacman\")) install.packages(\"pacman\")\n3pacman::p_load(tidyverse, magrittr, modelsummary, broom)\n\n\n\n1\n\n前の作業など，rのメモリに入っているものをリセットするコマンド\n\n2\n\nパッケージ管理用のパッケージであるpacmanが入っていない場合はインストール\n\n3\n\n必要なパッケージを読み込み\n\n\n\n\n\n6.1.1 5.1\n\n1.\n\n\nCode\nicecream %$%\n  lm(icecream ~ income + u15) %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = icecream ~ income + u15)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1665.6  -478.8  -118.6   613.2  2039.1 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  7.223e+03  2.114e+03   3.417  0.00134 **\nincome       6.424e-04  2.830e-04   2.270  0.02795 * \nu15         -8.795e+03  1.476e+04  -0.596  0.55403   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 871.7 on 46 degrees of freedom\nMultiple R-squared:  0.1039,    Adjusted R-squared:  0.0649 \nF-statistic: 2.666 on 2 and 46 DF,  p-value: 0.08028\n\n\n\n\n2.\n\n\nCode\nresult1 &lt;- icecream %$%\n  lm(icecream ~ income + u15)\n\nmsummary(result1,\n         statistic = \" [{conf.low}, {conf.high}]\")\n\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n7222.763\n\n\n\n[2967.362, 11478.165]\n\n\nincome\n0.001\n\n\n\n[0.000, 0.001]\n\n\nu15\n−8795.471\n\n\n\n[−38495.860, 20904.918]\n\n\nNum.Obs.\n49\n\n\nR2\n0.104\n\n\nR2 Adj.\n0.065\n\n\nAIC\n807.5\n\n\nBIC\n815.0\n\n\nLog.Lik.\n−399.730\n\n\nF\n2.666\n\n\nRMSE\n844.57\n\n\n\n\n\n\n\n\n\n\n6.1.2 5.2\n\n\nCode\ntem_aug &lt;- read_csv(\"data/R_EmpiricalAnalysis_csv/chap04/temperature_aug.csv\")\ntem_aug\n\n\n\n\n  \n\n\n\n\n\nCode\ntem_aug %&lt;&gt;%\n  mutate(morning = 1* (6 &lt;= time & time &lt;=12 ),\n         afternoon = 1 * (13 &lt;= time & time &lt;=18 ))\ntem_aug\n\n\n\n\n  \n\n\n\n\n\nCode\ntem_aug %&lt;&gt;%\n  mutate(date = ymd(date),\n         dow = wday(date,label = TRUE),\n         saturday = 1 * (dow == \"Sat\"))\n\ntem_aug %&lt;&gt;%\n  mutate(sunday = 1 * (dow == \"Sun\"),\n         recess = 1 * (\"2014-08-11\"&lt;=date &\"2014-08-11\"&lt;=date ))\n\n\n  \n#  mutate(saturday = 1 * ((date == \"2014/8/2\")|\n#                         (date == \"2014/8/9\")|\n#                         (date == \"2014/8/16\")|\n#                         (date == \"2014/8/23\")|\n#                         (date == \"2014/8/30\")\n#  ))\n\n\n\n\nCode\nreg4_1 &lt;-tem_aug %$%\n  lm(elec ~ temp + prec + sunday + recess + morning + afternoon + saturday)\nsummary(reg4_1)\n\n\n\nCall:\nlm(formula = elec ~ temp + prec + sunday + recess + morning + \n    afternoon + saturday)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1030.02  -347.04    30.51   319.40  1012.10 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  244.956    153.145   1.600 0.110138    \ntemp         113.321      5.176  21.895  &lt; 2e-16 ***\nprec          14.677     16.730   0.877 0.380621    \nsunday      -409.299     43.531  -9.402  &lt; 2e-16 ***\nrecess      -127.016     36.236  -3.505 0.000484 ***\nmorning      215.088     38.074   5.649 2.30e-08 ***\nafternoon    589.475     40.687  14.488  &lt; 2e-16 ***\nsaturday    -260.407     43.640  -5.967 3.75e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 419.8 on 736 degrees of freedom\nMultiple R-squared:  0.6579,    Adjusted R-squared:  0.6547 \nF-statistic: 202.2 on 7 and 736 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nmsummary(reg4_1,\n         statistic = \" [{conf.low}, {conf.high}]\")\n\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n244.956\n\n\n\n[−55.697, 545.609]\n\n\ntemp\n113.321\n\n\n\n[103.160, 123.482]\n\n\nprec\n14.677\n\n\n\n[−18.168, 47.522]\n\n\nsunday\n−409.299\n\n\n\n[−494.759, −323.839]\n\n\nrecess\n−127.016\n\n\n\n[−198.154, −55.879]\n\n\nmorning\n215.088\n\n\n\n[140.342, 289.835]\n\n\nafternoon\n589.475\n\n\n\n[509.598, 669.351]\n\n\nsaturday\n−260.407\n\n\n\n[−346.080, −174.733]\n\n\nNum.Obs.\n744\n\n\nR2\n0.658\n\n\nR2 Adj.\n0.655\n\n\nAIC\n11108.4\n\n\nBIC\n11149.9\n\n\nLog.Lik.\n−5545.210\n\n\nF\n202.244\n\n\nRMSE\n417.51\n\n\n\n\n\n\n\n\n\n6.1.3 5.3\n\n\nCode\nS &lt;- 10000\nbox &lt;- numeric(S)\n\n\nfor(i in 1:S){\n  x &lt;- rnorm(1000,0,1)\n  y &lt;- 1+5*x+rnorm(1000,0,1)\n  res &lt;- lm(y~x) %&gt;% summary() %&gt;% tidy()\n  beta1 &lt;- res$estimate[2]\n  sigma1 &lt;-res$std.error[2]\n  box[i] &lt;- (abs(beta1 -5) &lt; 1.96 * sigma1)\n}\nmean(box)\n\n\n[1] 0.9517"
  },
  {
    "objectID": "class/7_kentei.html#footnotes",
    "href": "class/7_kentei.html#footnotes",
    "title": "7 検定",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n高校数学でやりましたか？歪んだコインって見たことないですよね。↩︎"
  },
  {
    "objectID": "class/1_intro.html#定義",
    "href": "class/1_intro.html#定義",
    "title": "1 イントロダクション",
    "section": "2.1 定義",
    "text": "2.1 定義\nこの授業では， 佐藤 (2015a, 31) に従い社会調査を以下のようなものとする。\n\n理論的枠組みや先行研究を踏まえて適切な問いを立て，確実な調査技法を用いて良質のデータを獲得し，的確な方法で分析を行うことによって，問いに対する答えを導き出す\n\n社会調査は，新しい知識や情報を得るために，システマティックに探求されるもの (佐藤 2015a, 25)\n\n2.1.1 新しい知識と情報?\n\n調査というものは，そもそもまだ誰も知らない何かを知るために行われるもの。\n\n新しい知見を得るために行われている\n特に社会的もしくは理論的に重要だけどわかっていない何かを明らかにしたい\n\n\n\n\n2.1.2 システマティックに探求？\n\n社会科学の領域で広く認められた手順や方法を踏まえて調査する\n\n適当な方法では，明らかにしたいことがわからない\nもっと酷い場合は間違った結論を出してしまうかもしれない\n\n適切な方法で獲得したデータを，的確な方法で分析することで，問いに対する答えを証拠を持って提示する"
  },
  {
    "objectID": "class/1_intro.html#プログラミング言語rを使った分析方法の習得",
    "href": "class/1_intro.html#プログラミング言語rを使った分析方法の習得",
    "title": "1 イントロダクション",
    "section": "4.2 プログラミング言語Rを使った分析方法の習得",
    "text": "4.2 プログラミング言語Rを使った分析方法の習得\n\nこの授業では，特に統計的な処理にRというプログラミング言語を使います\nRは特に統計分析に特化したプログラミング言語で，Pythonのような汎用性がない代わりに，統計的な処理に関わる機能や操作性が高いです\n\nただし，統計処理に関わる前後の処理も得意で，例えばレポートやスライド資料も作れます\n\n\n\n\n\n\n\n\nNote\n\n\n\nこの授業資料も全部Rで作っています"
  },
  {
    "objectID": "class/1_intro.html#全体像",
    "href": "class/1_intro.html#全体像",
    "title": "1 イントロダクション",
    "section": "5.1 全体像",
    "text": "5.1 全体像\n上記の通り，社会調査のプロセスのうち，特に定量的分析部分を中心に，以下のような順番で進めます。\n\nイントロダクション\n分析環境の構築\nデータの種類とまとめ方\nデータを要約する（1変数）\nデータを要約する（複数変数）\n母集団と標本\n検定\n回帰分析\n重回帰分析\nダミー変数・交互作用・対数回帰\n実験と分散分析\n内生変数・外生変数と因果推論\n質問表調査の作成\n分析の実習\n社会調査法のまとめ"
  },
  {
    "objectID": "class/1_intro.html#授業中",
    "href": "class/1_intro.html#授業中",
    "title": "1 イントロダクション",
    "section": "5.2 授業中",
    "text": "5.2 授業中\n\n授業中は，こちらからのレクチャーと，（主に）Rを使った実習からなります\n\nレクチャーでやったことを\n自分で実装\n\n\n\n\n\n\n\n\nCaution\n\n\n\n毎回パソコンを持ってきてください！"
  },
  {
    "objectID": "class/1_intro.html#評価",
    "href": "class/1_intro.html#評価",
    "title": "1 イントロダクション",
    "section": "5.3 評価",
    "text": "5.3 評価\n\nこの授業の評価は以下の基準で行います\n\n授業中の実習 (50%)\n\nコードの提出\n\n調査レポート (50%)\n\n自身で問題を設定し，自身で得たデータを分析することを通して答える"
  }
]